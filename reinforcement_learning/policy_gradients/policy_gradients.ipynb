{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 0. Simple Policy Function\n",
    "def policy(matrix, weight):\n",
    "    \"\"\"\n",
    "    Computes a policy using the given weight for the provided matrix\n",
    "\n",
    "    Args:\n",
    "        matrix: np.ndarray shape (state, action)\n",
    "        weight: np.ndarray shape (action, weight)\n",
    "\n",
    "    Returns:\n",
    "        The policy computed using the given weight\n",
    "        np.ndarray shape (state, weight)\n",
    "    \"\"\"\n",
    "    dot_prod = matrix.dot(weight)\n",
    "    exp = np.exp(dot_prod)\n",
    "    policy = exp / np.sum(exp)\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.50351642 0.49648358]]\n"
     ]
    }
   ],
   "source": [
    "# 0-main\n",
    "weight = np.ndarray((4, 2), buffer=np.array([\n",
    "    [4.17022005e-01, 7.20324493e-01], \n",
    "    [1.14374817e-04, 3.02332573e-01], \n",
    "    [1.46755891e-01, 9.23385948e-02], \n",
    "    [1.86260211e-01, 3.45560727e-01]\n",
    "    ]))\n",
    "state = np.ndarray((1, 4), buffer=np.array([\n",
    "    [-0.04428214,  0.01636746,  0.01196594, -0.03095031]\n",
    "    ]))\n",
    "\n",
    "res = policy(state, weight)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1. Compute the Monte-Carlo policy gradient\n",
    "def policy_gradient(state, weight):\n",
    "    \"\"\"\n",
    "    Function that computes the Monte-Carlo policy gradient based on a state\n",
    "        and a weight matrix\n",
    "\n",
    "    Args:\n",
    "        state: matrix representing the current observation of the environment\n",
    "        weight: matrix of random weight\n",
    "\n",
    "    Returns:\n",
    "        The action and the gradieng(in this order)\n",
    "    \"\"\"\n",
    "    MCPolicy = policy(state, weight)\n",
    "    action = np.random.choice(len(MCPolicy[0]), p=MCPolicy[0])\n",
    "\n",
    "    # Need to reshape the policy to build softmax, so we do that here\n",
    "    s = MCPolicy.reshape(-1, 1)\n",
    "\n",
    "    softmax = (np.diagflat(s) - np.dot(s, s.T))[action, :]\n",
    "\n",
    "    log_derivative = softmax / MCPolicy[0, action]\n",
    "\n",
    "    grad = state.T.dot(log_derivative[None, :])\n",
    "\n",
    "    return action, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.17022005e-01 7.20324493e-01]\n",
      " [1.14374817e-04 3.02332573e-01]\n",
      " [1.46755891e-01 9.23385948e-02]\n",
      " [1.86260211e-01 3.45560727e-01]]\n",
      "[[ 0.04124436  0.00458376  0.0449007  -0.04867243]]\n",
      "0\n",
      "[[ 0.02066031 -0.02066031]\n",
      " [ 0.00229612 -0.00229612]\n",
      " [ 0.02249186 -0.02249186]\n",
      " [-0.02438121  0.02438121]]\n"
     ]
    }
   ],
   "source": [
    "# 1-main\n",
    "env = gym.make('CartPole-v1')\n",
    "np.random.seed(1)\n",
    "\n",
    "weight = np.random.rand(4, 2)\n",
    "state = env.reset()[None,:]\n",
    "print(weight)\n",
    "print(state)\n",
    "\n",
    "action, grad = policy_gradient(state, weight)\n",
    "print(action)\n",
    "print(grad)\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
