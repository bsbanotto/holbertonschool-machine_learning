{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.disable_v2_behavior()\n",
    "import tensorflow.compat.v1.keras as K\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 0. Convolutional Forward Prop\n",
    "\"\"\"\n",
    "Write a function that performs forward propagation over a convolutional layer\n",
    "of a neural network.\n",
    "\"\"\"\n",
    "def conv_forward(A_prev, W, b, activation, padding=\"same\", stride=(1, 1)):\n",
    "    \"\"\"\n",
    "    A_prev: numpy.ndarray of shape (m, h_prev, w_prev, c_prev) containing the\n",
    "    output of the previous layer\n",
    "        m: number of examples\n",
    "        h_prev: height of the previous layer\n",
    "        w_prev: width of the previous layer\n",
    "        c_prev: number of channels in the previous layer\n",
    "    W: numpy.ndarray of shape (kh, kw, c_prev, c_new) containing the kernels\n",
    "    for the convolution\n",
    "        kh: filter height\n",
    "        kw: filter width\n",
    "        c_prev: number of channels in the previous layer\n",
    "        c_new: number of channels in the output\n",
    "    b: numpy.ndarray of shape (1, 1, 1, c_new) containing the biases applied\n",
    "    to the convolution\n",
    "    activation: an activation function applied to the convolution\n",
    "    padding: string that is either 'same' or 'valid' indicating the type of\n",
    "    padding used\n",
    "    stride: tuple of shape (sh, sw) containing the strides for the convolution\n",
    "        sh: stride for the height\n",
    "        sw: stride for the width\n",
    "    Returns the output of the convolution layer\n",
    "    \"\"\"\n",
    "\n",
    "    m = A_prev.shape[0]\n",
    "    h_prev = A_prev.shape[1]\n",
    "    w_prev = A_prev.shape[2]\n",
    "    c_prev = A_prev.shape[3]\n",
    "\n",
    "    kh = W.shape[0]\n",
    "    kw = W.shape[1]\n",
    "    kc_prev = W.shape[2]\n",
    "    kc_new = W.shape[3]\n",
    "\n",
    "    sh = stride[0]\n",
    "    sw = stride[1]\n",
    "\n",
    "    if padding == 'same':\n",
    "        pad_top_bottom = (((h_prev - 1) * sh) + kh - h_prev) // 2\n",
    "        pad_left_right = (((w_prev - 1) * sw) + kw - w_prev) // 2\n",
    "\n",
    "    if padding == 'valid':\n",
    "        pad_top_bottom = 0\n",
    "        pad_left_right = 0\n",
    "\n",
    "    A_prev = np.pad(A_prev, ((0, 0), (pad_top_bottom, pad_top_bottom),\n",
    "                                 (pad_left_right, pad_left_right), (0, 0)))\n",
    "\n",
    "    h_prev = (h_prev + 2 * pad_top_bottom - kh) // sh + 1\n",
    "    w_prev = (w_prev + 2 * pad_left_right - kw) // sw + 1\n",
    "\n",
    "    conv_image = np.zeros((m, h_prev, w_prev, kc_new))\n",
    "\n",
    "    for x in range (h_prev):\n",
    "        for y in range (w_prev):\n",
    "            for z in range (kc_new):\n",
    "                i = x * sh\n",
    "                j = y * sw\n",
    "                hadamard_prod = np.multiply(A_prev[:, i:i + kh, j:j + kw, :],\n",
    "                                            W[:, :, :, z])\n",
    "                conv_image[:, x, y, z] = np.sum(hadamard_prod, axis=(1, 2, 3))\n",
    "\n",
    "    return activation(conv_image + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-main\n",
    "np.random.seed(0)\n",
    "lib = np.load('../data/MNIST.npz')\n",
    "X_train = lib['X_train']\n",
    "m, h, w = X_train.shape\n",
    "X_train_c = X_train.reshape((-1, h, w, 1))\n",
    "\n",
    "W = np.random.randn(3, 3, 1, 2)\n",
    "b = np.random.randn(1, 1, 1, 2)\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "plt.imshow(X_train[0])\n",
    "plt.show()\n",
    "A = conv_forward(X_train_c, W, b, relu, padding='valid')\n",
    "print(A.shape)\n",
    "plt.imshow(A[0, :, :, 0])\n",
    "plt.show()\n",
    "plt.imshow(A[0, :, :, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1. Pooling Forward Prop\n",
    "\"\"\"\n",
    "Write a function that performs forward propagation over a pooling layer of a\n",
    "neural network\n",
    "\"\"\"\n",
    "def pool_forward(A_prev, kernel_shape, stride=(1, 1), mode='max'):\n",
    "    \"\"\"\n",
    "    A_prev: numpy.ndarray of shape (m, h_prev, w_prev, c_prev) containing the\n",
    "    output of the previous layer\n",
    "        m: number of examples\n",
    "        h_prev: height of the previous layer\n",
    "        w_prev: width of the previous layer\n",
    "        c_prev: number of channels in the previous layer\n",
    "    kernel_shape: numpy.ndarray of shape (kh, kw) containing the kernels\n",
    "    for the convolution\n",
    "        kh: filter height\n",
    "        kw: filter width\n",
    "    stride: tuple of shape (sh, sw) containing the strides for the convolution\n",
    "        sh: stride for the height\n",
    "        sw: stride for the width\n",
    "    mode: string containing either 'max' or 'avg', indicating whether to\n",
    "    perform maximum or average pooling\n",
    "    Returns the output of the pooling layer\n",
    "    \"\"\"\n",
    "    m = A_prev.shape[0]\n",
    "    h = A_prev.shape[1]\n",
    "    w = A_prev.shape[2]\n",
    "    c = A_prev.shape[3]\n",
    "\n",
    "    kh = kernel_shape[0]\n",
    "    kw = kernel_shape[1]\n",
    "\n",
    "    sh = stride[0]\n",
    "    sw = stride[1]\n",
    "\n",
    "    h = (h - kh) // sh + 1\n",
    "    w = (w - kw) // sw + 1\n",
    "\n",
    "    output_image = np.zeros((m, h, w, c))\n",
    "\n",
    "    for x in range(h):\n",
    "        for y in range(w):\n",
    "            i = x * sh\n",
    "            j = y * sw\n",
    "            if mode == 'max':\n",
    "                output_image[:, x, y, :] = np.max(A_prev[:,\n",
    "                                                         i:i + kh,\n",
    "                                                         j:j + kw,\n",
    "                                                         :], axis=(1, 2))\n",
    "            if mode == 'avg':\n",
    "                output_image[:, x, y, :] = np.mean(A_prev[:,\n",
    "                                                          i:i + kh,\n",
    "                                                          j:j + kw,\n",
    "                                                          :], axis=(1, 2))\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-main\n",
    "np.random.seed(0)\n",
    "lib = np.load('../data/MNIST.npz')\n",
    "X_train = lib['X_train']\n",
    "m, h, w = X_train.shape\n",
    "X_train_a = X_train.reshape((-1, h, w, 1))\n",
    "X_train_b = 1 - X_train_a\n",
    "X_train_c = np.concatenate((X_train_a, X_train_b), axis=3)\n",
    "\n",
    "print(X_train_c.shape)\n",
    "plt.imshow(X_train_c[0, :, :, 0])\n",
    "plt.show()\n",
    "plt.imshow(X_train_c[0, :, :, 1])\n",
    "plt.show()\n",
    "A = pool_forward(X_train_c, (2, 2), stride=(2, 2))\n",
    "print(A.shape)\n",
    "plt.imshow(A[0, :, :, 0])\n",
    "plt.show()\n",
    "plt.imshow(A[0, :, :, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2. Convolutional Back Prop\n",
    "\"\"\"\n",
    "Write a function that performs back propagation over a convolutional layer of\n",
    "a neural network\n",
    "\"\"\"\n",
    "def conv_backward(dZ, A_prev, W, b, padding=\"same\", stride=(1, 1)):\n",
    "    \"\"\"\n",
    "    dZ: numpy.ndarray of shape (m, h_new, w_new, c_new) containing the partial\n",
    "    derivatives with respect to the unactivated output of the convolutional\n",
    "    layer\n",
    "        m: number of examples\n",
    "        h_new: height of the output\n",
    "        w_new: width of the output\n",
    "        c_new: number of channels in the output\n",
    "    A_prev: numpy.ndarray of shape (m, h_prev, w_prev, c_prev) containing the\n",
    "    output of the previous layer\n",
    "        m: number of examples\n",
    "        h_prev: height of the previous layer\n",
    "        w_prev: width of the previous layer\n",
    "        c_prev: number of channels in the previous layer\n",
    "    W: numpy.ndarray of shape (kh, kw, c_prev, c_new) containing the kernels\n",
    "    for the convolution\n",
    "        kh: filter height\n",
    "        kw: filter width\n",
    "        c_prev: number of channels in the previous layer\n",
    "        c_new: number of channels in the output\n",
    "    b: numpy.ndarray of shape (1, 1, 1, c_new) containing the biases applied\n",
    "    to the convolution\n",
    "    stride: tuple of shape (sh, sw) containing the strides for the convolution\n",
    "        sh: stride for the height\n",
    "        sw: stride for the width\n",
    "    Returns the partial derivatives with respect to the previous layer\n",
    "    (dA_prev), the kernels (dW) and the biases(db), respectively\n",
    "    \"\"\"\n",
    "    m = dZ.shape[0]\n",
    "    h_new = dZ.shape[1]\n",
    "    w_new = dZ.shape[2]\n",
    "    c_new = dZ.shape[3]\n",
    "\n",
    "    h_prev = A_prev.shape[1]\n",
    "    w_prev = A_prev.shape[2]\n",
    "    c_prev = A_prev.shape[3]\n",
    "\n",
    "    kh = W.shape[0]\n",
    "    kw = W.shape[1]\n",
    "\n",
    "    sh = stride[0]\n",
    "    sw = stride[1]\n",
    "\n",
    "    dA_prev = np.zeros_like(A_prev)\n",
    "    dW = np.zeros_like(W)\n",
    "    db = np.sum(dZ, axis=(0, 1, 2), keepdims=True)\n",
    "\n",
    "    if padding == 'same':\n",
    "        pad_top_bottom = (((h_prev - 1) * sh) + kh - h_prev) // 2 + 1\n",
    "        pad_left_right = (((w_prev - 1) * sw) + kw - w_prev) // 2 + 1\n",
    "\n",
    "    if padding == 'valid':\n",
    "        pad_top_bottom = 0\n",
    "        pad_left_right = 0\n",
    "\n",
    "    A_prev = np.pad(A_prev, ((0, 0), (pad_top_bottom, pad_top_bottom),\n",
    "                    (pad_left_right, pad_left_right), (0, 0)))\n",
    "\n",
    "    dA_prev = np.pad(dA_prev, ((0, 0), (pad_top_bottom, pad_top_bottom),\n",
    "                (pad_left_right, pad_left_right), (0, 0)))\n",
    "\n",
    "    for image in range(m):\n",
    "        for x in range (h_new):\n",
    "            for y in range (w_new):\n",
    "                for z in range (c_new):\n",
    "                    i = x * sh\n",
    "                    j = y * sw\n",
    "                    dW[:, :, :, z] += np.multiply(A_prev[image, i:i + kh, j:j + kw, :], dZ[image, x, y, z])\n",
    "                    dA_prev[image, i:i + kh, j:j + kw, :] += np.multiply(W[:, :, :, z], dZ[image, x, y, z])\n",
    "\n",
    "    if padding == 'same':\n",
    "        dA_prev = dA_prev[:, pad_top_bottom:-pad_top_bottom,\n",
    "                          pad_left_right:-pad_left_right, :]\n",
    "\n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-main\n",
    "np.random.seed(4)\n",
    "m = np.random.randint(100, 200)\n",
    "h, w = np.random.randint(20, 50, 2).tolist()\n",
    "cin = np.random.randint(2, 5)\n",
    "cout = np.random.randint(5, 10)\n",
    "fh, fw = (np.random.randint(2, 5, 2)).tolist()\n",
    "sh, sw = (np.random.randint(2, 4, 2)).tolist()\n",
    "\n",
    "X = np.random.uniform(0, 1, (m, h, w, cin))\n",
    "W = np.random.uniform(0, 1, (fh, fw, cin, cout))\n",
    "b = np.random.uniform(0, 1, (1, 1, 1, cout))\n",
    "dZ = np.random.uniform(0, 1, (m, (h - fh) // sh + 1, (w - fw) // sw + 1, cout))\n",
    "dA, dW, db = conv_backward(dZ, X, W, b, padding=\"valid\", stride=(sh, sw))\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "# print(dA)\n",
    "# print(dA.shape)\n",
    "print(dW)\n",
    "print(dW.shape)\n",
    "print(db)\n",
    "print(db.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3. Pooling Back Prop\n",
    "\"\"\"\n",
    "Write a function that performs back propagation over a pooling layer of a \n",
    "neural network\n",
    "\"\"\"\n",
    "np.set_printoptions(suppress=True)\n",
    "def pool_backward(dA, A_prev, kernel_shape, stride=(1, 1), mode='max'):\n",
    "    \"\"\"\n",
    "    dA: numpy.ndarray of shape (m, h_new, w_new, c_new) containing the partial\n",
    "    derivatives with respect to the output of the pooling layer\n",
    "        m: number of examples\n",
    "        h_new: height of the output\n",
    "        w_new: width of the output\n",
    "        c: number of channels\n",
    "    A_prev: numpy.ndarray of shape (m, h_prev, w_prev, c) containing the output\n",
    "    of the previous layer\n",
    "        m: number of examples\n",
    "        h_prev: height of the previous layer\n",
    "        w_prev: width of the previous layer\n",
    "        c: number of channels\n",
    "    kernel_shape: tuple of (kh, kw) containing the size of the kernel for\n",
    "    pooling\n",
    "        kh: kernel height\n",
    "        kw: kernel width\n",
    "    stride: tuple of (sh, sw) containing the strides for the pooling\n",
    "        sh: stride for the height\n",
    "        sw: stride for the width\n",
    "    mode: string containing either 'max' or 'avg' indicating whether to\n",
    "    perform maximum or average pooling, respectively\n",
    "    Returns the partial derivatives with respect to the previous layer\n",
    "    (dA_prev)\n",
    "    \"\"\"\n",
    "    m = dA.shape[0]\n",
    "    h_new = dA.shape[1]\n",
    "    w_new = dA.shape[2]\n",
    "    c_new = dA.shape[3]\n",
    "\n",
    "    h_prev = A_prev.shape[1]\n",
    "    w_prev = A_prev.shape[2]\n",
    "    c = A_prev.shape[3]\n",
    "\n",
    "    kh = kernel_shape[0]\n",
    "    kw = kernel_shape[1]\n",
    "\n",
    "    sh = stride[0]\n",
    "    sw = stride[1]\n",
    "\n",
    "    dA_prev = np.zeros_like(A_prev)\n",
    "\n",
    "    for image in range(m):\n",
    "        for x in range(h_new):\n",
    "            for y in range(w_new):\n",
    "                for z in range(c_new):\n",
    "                    i = sh * x\n",
    "                    j = sw * y\n",
    "                    if mode == 'max':\n",
    "                        a_prev_slice = A_prev[image, i:i + kh, j:j + kw, z]\n",
    "                        mask = (a_prev_slice == np.max(a_prev_slice))\n",
    "                        dA_prev[image, i:i + kh, j:j + kw, z] += (mask * dA[image, x, y, z])\n",
    "                    if mode == 'avg':\n",
    "                        avgerage_dA = dA[image, x, y, z] / kh / kw\n",
    "                        dA_prev[image, i:i + kh, j:j + kw, z] += np.ones(\n",
    "                            (kh, kw)) * avgerage_dA\n",
    "    return dA_prev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-main\n",
    "np.random.seed(0)\n",
    "lib = np.load('../data/MNIST.npz')\n",
    "X_train = lib['X_train']\n",
    "_, h, w = X_train.shape\n",
    "X_train_a = X_train[:10].reshape((-1, h, w, 1))\n",
    "X_train_b = 1 - X_train_a\n",
    "X_train_c = np.concatenate((X_train_a, X_train_b), axis=3)\n",
    "\n",
    "dA = np.random.randn(10, h // 3, w // 3, 2)\n",
    "print(pool_backward(dA, X_train_c, (3, 3), stride=(3, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4. LeNet-5 (Tensorflow)\n",
    "\"\"\"\n",
    "Write a function that builds a modified version of the LeNet-5 architecture\n",
    "using tensorflow\n",
    "\"\"\"\n",
    "def lenet5(x, y):\n",
    "    \"\"\"\n",
    "    x: tf.placeholder of shape (m, 28, 28, 1) containing the input images for\n",
    "    the network\n",
    "        m: number of images\n",
    "    y: tf.placeholder of shape (m, 10) containing the one-hot labels for the \n",
    "    network\n",
    "    The model should consist of the following layers in order:\n",
    "        Convolutional layer with 6 kernels of shape 5x5 with `same` padding\n",
    "        Max pooling layer with kernels of shape 2x2 with 2x2 strides\n",
    "        Convolutional layer with 16 kernels of shape 5x5 with `valid` padding\n",
    "        Max pooling layer with kernels of shape 2x2 with 2x2 strides\n",
    "        Fully connected layer with 120 nodes\n",
    "        Fully connected layer with 84 nodes\n",
    "        Fully connected softmax output layer with 10 nodes\n",
    "    All layers requiring initialization should initialize their kernels with\n",
    "    he_normal initialization method:\n",
    "        tf.contrib.layers.variance_scaling_initializer()\n",
    "    All hidden layers requiring activation should use the relu activation\n",
    "    function\n",
    "    Returns:\n",
    "        a tensor for the softmax activated output\n",
    "        a training operation that utilizes Adam optimization\n",
    "        a tensor for the loss of the network\n",
    "        a tensor for the accuracy of the network\n",
    "    \"\"\"\n",
    "    init = tf.keras.initializers.VarianceScaling()\n",
    "\n",
    "    convolutional1 = tf.layers.conv2d(inputs=x,\n",
    "                                      filters=6,\n",
    "                                      kernel_size=(5, 5),\n",
    "                                      padding='same',\n",
    "                                      activation='relu',\n",
    "                                      kernel_initializer=init)\n",
    "\n",
    "    max_pooling1 = tf.layers.max_pooling2d(inputs=convolutional1,\n",
    "                                           pool_size=(2, 2),\n",
    "                                           strides=(2, 2))\n",
    "\n",
    "    convolutional2 = tf.layers.conv2d(inputs=max_pooling1,\n",
    "                                      filters=16,\n",
    "                                      kernel_size=(5, 5),\n",
    "                                      padding='valid',\n",
    "                                      activation='relu',\n",
    "                                      kernel_initializer=init)\n",
    "\n",
    "    max_pooling2 = tf.layers.max_pooling2d(inputs=convolutional2,\n",
    "                                           pool_size=(2, 2),\n",
    "                                           strides=(2, 2))\n",
    "\n",
    "    flat_pool = tf.layers.flatten(max_pooling2)\n",
    "\n",
    "    fully_connected_1 = tf.layers.dense(inputs=flat_pool,\n",
    "                                        units=120,\n",
    "                                        activation='relu',\n",
    "                                        kernel_initializer=init,\n",
    "                                        )\n",
    "\n",
    "    fully_connected_2 = tf.layers.dense(inputs=fully_connected_1,\n",
    "                                        units=84,\n",
    "                                        activation='relu',\n",
    "                                        kernel_initializer=init,\n",
    "                                        )\n",
    "\n",
    "    fully_connected_3 = tf.layers.dense(inputs=fully_connected_2,\n",
    "                                        units=10,\n",
    "                                        kernel_initializer=init)\n",
    "\n",
    "    softmax = tf.nn.softmax(fully_connected_3)\n",
    "\n",
    "    loss = tf.losses.softmax_cross_entropy(onehot_labels=y,\n",
    "                                           logits=fully_connected_3)\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "    y_max = tf.math.argmax(y, axis=1)\n",
    "    y_pred_max = tf.math.argmax(fully_connected_3, axis=1)\n",
    "    equality = tf.math.equal(y_max, y_pred_max)\n",
    "    accuracy = tf.math.reduce_mean(tf.cast(equality, tf.float32))\n",
    "\n",
    "    return softmax, optimizer, loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-main\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)\n",
    "lib = np.load('../data/MNIST.npz')\n",
    "X_train = lib['X_train']\n",
    "Y_train = lib['Y_train']\n",
    "X_valid = lib['X_valid']\n",
    "Y_valid = lib['Y_valid']\n",
    "m, h, w = X_train.shape\n",
    "X_train_c = X_train.reshape((-1, h, w, 1))\n",
    "X_valid_c = X_valid.reshape((-1, h, w, 1))\n",
    "x = tf.placeholder(tf.float32, (None, h, w, 1))\n",
    "y = tf.placeholder(tf.int32, (None,))\n",
    "y_oh = tf.one_hot(y, 10)\n",
    "y_pred, train_op, loss, acc = lenet5(x, y_oh)\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(epochs):\n",
    "        cost, accuracy = sess.run((loss, acc), feed_dict={x:X_train_c, y:Y_train})\n",
    "        cost_valid, accuracy_valid = sess.run((loss, acc), feed_dict={x:X_valid_c, y:Y_valid})\n",
    "        print(\"After {} epochs: {} cost, {} accuracy, {} validation cost, {} validation accuracy\".format(epoch, cost, accuracy, cost_valid, accuracy_valid))\n",
    "        p = np.random.permutation(m)\n",
    "        X_shuffle = X_train_c[p]\n",
    "        Y_shuffle = Y_train[p]\n",
    "        for i in range(0, m, batch_size):\n",
    "            X_batch = X_shuffle[i:i+batch_size]\n",
    "            Y_batch = Y_shuffle[i:i+batch_size]\n",
    "            sess.run(train_op, feed_dict={x:X_batch, y:Y_batch})\n",
    "    cost, accuracy = sess.run((loss, acc), feed_dict={x:X_train_c, y:Y_train})\n",
    "    cost_valid, accuracy_valid = sess.run((loss, acc), feed_dict={x:X_valid_c, y:Y_valid})\n",
    "    print(\"After {} epochs: {} cost, {} accuracy, {} validation cost, {} validation accuracy\".format(epochs, cost, accuracy, cost_valid, accuracy_valid))\n",
    "    Y_pred = sess.run(y_pred, feed_dict={x:X_valid_c, y:Y_valid})\n",
    "    print(Y_pred[0])\n",
    "    Y_pred = np.argmax(Y_pred, 1)\n",
    "    plt.imshow(X_valid[0])\n",
    "    plt.title(str(Y_valid[0]) + ' : ' + str(Y_pred[0]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5. LeNet-5 (Keras)\n",
    "\"\"\"\n",
    "Write a function that builds a modified version of the LeNet-5 architecutre\n",
    "using Keras\n",
    "\"\"\"\n",
    "def lenet5(X):\n",
    "    \"\"\"\n",
    "    X: K.Input of shape (m, 28, 28, 1) containing the input images for the\n",
    "    network\n",
    "        m: number of images\n",
    "    The model should consist of the following layers in order:\n",
    "        Convolutional layer with 6 kernels of shape 5x5 with `same` padding\n",
    "        Max pooling layer with kernels of shape 2x2 with 2x2 strides\n",
    "        Convolutional layer with 16 kernels of shape 5x5 with `valid` padding\n",
    "        Max pooling layer with kernels of shape 2x2 with 2x2 strides\n",
    "        Fully connected layer with 120 nodes\n",
    "        Fully connected layer with 84 nodes\n",
    "        Fully connected softmax output layer with 10 nodes\n",
    "    All layers requiring initialization should initialize their kernels with\n",
    "    the he_normal initialization method\n",
    "    All hidden layers requiring activation should use the relu activation\n",
    "    function\n",
    "    Returns a K.Model compiled to use Adam optimization and accuracy metrics\n",
    "    \"\"\"\n",
    "    init = K.initializers.he_normal()\n",
    "\n",
    "    convolutional1 = K.layers.Conv2D(filters=6,\n",
    "                                     kernel_size=(5, 5),\n",
    "                                     padding='same',\n",
    "                                     activation='relu',\n",
    "                                     kernel_initializer=init)(X)\n",
    "\n",
    "    max_pooling1 = K.layers.MaxPooling2D(pool_size=(2, 2),\n",
    "                                         strides=(2, 2))(convolutional1)\n",
    "\n",
    "    convolutional2 = K.layers.Conv2D(filters=16,\n",
    "                                     kernel_size=(5, 5),\n",
    "                                     padding='valid',\n",
    "                                     activation='relu',\n",
    "                                     kernel_initializer=init)(max_pooling1)\n",
    "\n",
    "    max_pooling2 = K.layers.MaxPooling2D(pool_size=(2, 2),\n",
    "                                         strides=(2, 2))(convolutional2)\n",
    "\n",
    "    flat_pool = K.layers.Flatten()(max_pooling2)\n",
    "\n",
    "    fully_connected_1 = K.layers.Dense(units=120,\n",
    "                                       activation='relu',\n",
    "                                       kernel_initializer=init,\n",
    "                                       )(flat_pool)\n",
    "\n",
    "    fully_connected_2 = K.layers.Dense(units=84,\n",
    "                                       activation='relu',\n",
    "                                       kernel_initializer=init,\n",
    "                                       )(fully_connected_1)\n",
    "\n",
    "    fully_connected_3 = K.layers.Dense(units=10,\n",
    "                                       activation='softmax',\n",
    "                                       kernel_initializer=init\n",
    "                                       )(fully_connected_2)\n",
    "\n",
    "    model = K.models.Model(X, fully_connected_3)\n",
    "\n",
    "    model.compile(optimizer=K.optimizers.Adam(),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "   32/50000 [..............................] - ETA: 2:56 - loss: 2.6761 - acc: 0.0938"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 11:56:20.057716: W tensorflow/c/c_api.cc:291] Operation '{name:'total_1/Assign' id:836 op device:{requested: '', assigned: ''} def:{{{node total_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](total_1, total_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49696/50000 [============================>.] - ETA: 0s - loss: 0.1752 - acc: 0.9468"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsbanotto/.local/lib/python3.8/site-packages/keras/engine/training_v1.py:2333: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-03-13 11:56:29.024271: W tensorflow/c/c_api.cc:291] Operation '{name:'loss_1/mul' id:907 op device:{requested: '', assigned: ''} def:{{{node loss_1/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_1/mul/x, loss_1/dense_10_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 10s 199us/sample - loss: 0.1746 - acc: 0.9469 - val_loss: 0.0856 - val_acc: 0.9759\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 10s 198us/sample - loss: 0.0655 - acc: 0.9799 - val_loss: 0.0675 - val_acc: 0.9796\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 12s 249us/sample - loss: 0.0481 - acc: 0.9849 - val_loss: 0.0579 - val_acc: 0.9837\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 12s 231us/sample - loss: 0.0355 - acc: 0.9890 - val_loss: 0.0480 - val_acc: 0.9859\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 11s 215us/sample - loss: 0.0299 - acc: 0.9906 - val_loss: 0.0557 - val_acc: 0.9855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsbanotto/.local/lib/python3.8/site-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-03-13 11:57:14.720192: W tensorflow/c/c_api.cc:291] Operation '{name:'dense_10/Softmax' id:831 op device:{requested: '', assigned: ''} def:{{{node dense_10/Softmax}} = Softmax[T=DT_FLOAT, _has_manual_control_dependencies=true](dense_10/BiasAdd)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.4483534e-16 4.7181712e-09 2.7609690e-10 9.9999994e-01 7.8966083e-14\n",
      " 6.9623696e-10 1.4749382e-12 2.6733228e-11 7.9130027e-09 5.7207511e-12]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5-main\n",
    "\"\"\"\n",
    "Main file\n",
    "\"\"\"\n",
    "# Force Seed - fix for Keras\n",
    "SEED = 0\n",
    "# import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "import random\n",
    "random.seed(SEED)\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "# import tensorflow as tf\n",
    "tf.set_random_seed(SEED)\n",
    "# import tensorflow.keras as K\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.backend.set_session(sess)\n",
    "\n",
    "lib = np.load('../data/MNIST.npz')\n",
    "X_train = lib['X_train']\n",
    "m, h, w = X_train.shape\n",
    "X_train_c = X_train.reshape((-1, h, w, 1))\n",
    "Y_train = lib['Y_train']\n",
    "Y_train_oh = K.utils.to_categorical(Y_train, num_classes=10)\n",
    "X_valid = lib['X_valid']\n",
    "X_valid_c = X_valid.reshape((-1, h, w, 1))\n",
    "Y_valid = lib['Y_valid']\n",
    "Y_valid_oh = K.utils.to_categorical(Y_valid, num_classes=10)\n",
    "X = K.Input(shape=(h, w, 1))\n",
    "model = lenet5(X)\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "model.fit(X_train_c, Y_train_oh, batch_size=batch_size, epochs=epochs,\n",
    "                    validation_data=(X_valid_c, Y_valid_oh))\n",
    "Y_pred = model.predict(X_valid_c)\n",
    "print(Y_pred[0])\n",
    "Y_pred = np.argmax(Y_pred, 1)\n",
    "plt.imshow(X_valid[0])\n",
    "plt.title(str(Y_valid[0]) + ' : ' + str(Y_pred[0]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
