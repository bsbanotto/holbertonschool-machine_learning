{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.disable_v2_behavior()\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 0. Convolutional Forward Prop\n",
    "\"\"\"\n",
    "Write a function that performs forward propagation over a convolutional layer\n",
    "of a neural network.\n",
    "\"\"\"\n",
    "def conv_forward(A_prev, W, b, activation, padding=\"same\", stride=(1, 1)):\n",
    "    \"\"\"\n",
    "    A_prev: numpy.ndarray of shape (m, h_prev, w_prev, c_prev) containing the\n",
    "    output of the previous layer\n",
    "        m: number of examples\n",
    "        h_prev: height of the previous layer\n",
    "        w_prev: width of the previous layer\n",
    "        c_prev: number of channels in the previous layer\n",
    "    W: numpy.ndarray of shape (kh, kw, c_prev, c_new) containing the kernels\n",
    "    for the convolution\n",
    "        kh: filter height\n",
    "        kw: filter width\n",
    "        c_prev: number of channels in the previous layer\n",
    "        c_new: number of channels in the output\n",
    "    b: numpy.ndarray of shape (1, 1, 1, c_new) containing the biases applied\n",
    "    to the convolution\n",
    "    activation: an activation function applied to the convolution\n",
    "    padding: string that is either 'same' or 'valid' indicating the type of\n",
    "    padding used\n",
    "    stride: tuple of shape (sh, sw) containing the strides for the convolution\n",
    "        sh: stride for the height\n",
    "        sw: stride for the width\n",
    "    Returns the output of the convolution layer\n",
    "    \"\"\"\n",
    "\n",
    "    m = A_prev.shape[0]\n",
    "    h_prev = A_prev.shape[1]\n",
    "    w_prev = A_prev.shape[2]\n",
    "    c_prev = A_prev.shape[3]\n",
    "\n",
    "    kh = W.shape[0]\n",
    "    kw = W.shape[1]\n",
    "    kc_prev = W.shape[2]\n",
    "    kc_new = W.shape[3]\n",
    "\n",
    "    sh = stride[0]\n",
    "    sw = stride[1]\n",
    "\n",
    "    if padding == 'same':\n",
    "        pad_top_bottom = (((h_prev - 1) * sh) + kh - h_prev) // 2\n",
    "        pad_left_right = (((w_prev - 1) * sw) + kw - w_prev) // 2\n",
    "\n",
    "    if padding == 'valid':\n",
    "        pad_top_bottom = 0\n",
    "        pad_left_right = 0\n",
    "\n",
    "    A_prev = np.pad(A_prev, ((0, 0), (pad_top_bottom, pad_top_bottom),\n",
    "                                 (pad_left_right, pad_left_right), (0, 0)))\n",
    "\n",
    "    h_prev = (h_prev + 2 * pad_top_bottom - kh) // sh + 1\n",
    "    w_prev = (w_prev + 2 * pad_left_right - kw) // sw + 1\n",
    "\n",
    "    conv_image = np.zeros((m, h_prev, w_prev, kc_new))\n",
    "\n",
    "    for x in range (h_prev):\n",
    "        for y in range (w_prev):\n",
    "            for z in range (kc_new):\n",
    "                i = x * sh\n",
    "                j = y * sw\n",
    "                hadamard_prod = np.multiply(A_prev[:, i:i + kh, j:j + kw, :],\n",
    "                                            W[:, :, :, z])\n",
    "                conv_image[:, x, y, z] = np.sum(hadamard_prod, axis=(1, 2, 3))\n",
    "\n",
    "    return activation(conv_image + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-main\n",
    "np.random.seed(0)\n",
    "lib = np.load('../data/MNIST.npz')\n",
    "X_train = lib['X_train']\n",
    "m, h, w = X_train.shape\n",
    "X_train_c = X_train.reshape((-1, h, w, 1))\n",
    "\n",
    "W = np.random.randn(3, 3, 1, 2)\n",
    "b = np.random.randn(1, 1, 1, 2)\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "plt.imshow(X_train[0])\n",
    "plt.show()\n",
    "A = conv_forward(X_train_c, W, b, relu, padding='valid')\n",
    "print(A.shape)\n",
    "plt.imshow(A[0, :, :, 0])\n",
    "plt.show()\n",
    "plt.imshow(A[0, :, :, 1])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
