{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.disable_v2_behavior()\n",
    "import tensorflow.compat.v1.keras as K\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1. Inception Block\n",
    "\"\"\"\n",
    "Write a function that builds an inception block as described in Going Deeper\n",
    "with Convolutions (2014)\n",
    "\"\"\"\n",
    "def inception_block(A_prev, filters):\n",
    "    \"\"\"\n",
    "    A_prev: output from the previous layer\n",
    "    filters: tuple containing F1, F3R, F3, F5R, F5, FPP\n",
    "        F1: number of filters in the 1x1 convolution\n",
    "        F3R: number of filters in the 1x1 convolution before the 3x3\n",
    "        convolution\n",
    "        F3: number of filters in the 3x3 convolution\n",
    "        F5R: number of filters in the 1x1 convolution before the 5x5\n",
    "        convolution\n",
    "        F5: number of filters in the 5x5 convolution\n",
    "        FPP: number of filters in the 1x1 convolution after the max pooling\n",
    "    All convolutions inside the inception block should use a ReLU activation\n",
    "    Returns: the concatenated output of the inception block\n",
    "    \"\"\"\n",
    "    F1 = filters[0]\n",
    "    F3R = filters[1]\n",
    "    F3 = filters[2]\n",
    "    F5R = filters[3]\n",
    "    F5 = filters[4]\n",
    "    FPP = filters[5]\n",
    "\n",
    "    conv_1x1 = K.layers.Conv2D(filters=F1,\n",
    "                               kernel_size=(1, 1),\n",
    "                               padding='same',\n",
    "                               activation='relu'\n",
    "                               )(A_prev)\n",
    "\n",
    "    conv_1x1_3x3 = K.layers.Conv2D(filters=F3R,\n",
    "                                   kernel_size=(1, 1),\n",
    "                                   padding='same',\n",
    "                                   activation='relu'\n",
    "                                   )(A_prev)\n",
    "\n",
    "    conv_3x3 = K.layers.Conv2D(filters=F3,\n",
    "                               kernel_size=(3, 3),\n",
    "                               padding='same',\n",
    "                               activation='relu'\n",
    "                               )(conv_1x1_3x3)\n",
    "\n",
    "    conv_1x1_5x5 = K.layers.Conv2D(filters=F5R,\n",
    "                                   kernel_size=(1, 1),\n",
    "                                   padding='same',\n",
    "                                   activation='relu'\n",
    "                                   )(A_prev)\n",
    "\n",
    "    conv_5x5 = K.layers.Conv2D(filters=F5,\n",
    "                               kernel_size=(5, 5),\n",
    "                               padding='same',\n",
    "                               activation='relu'\n",
    "                               )(conv_1x1_5x5)\n",
    "\n",
    "    max_pool_3x3 = K.layers.MaxPooling2D(pool_size=(3, 3),\n",
    "                                         strides=1,\n",
    "                                         padding='same'\n",
    "                                         )(A_prev)\n",
    "\n",
    "    conv_1x1_pooled = K.layers.Conv2D(filters=FPP,\n",
    "                                      kernel_size=(1, 1),\n",
    "                                      padding='same',\n",
    "                                      activation='relu'\n",
    "                                      )(max_pool_3x3)\n",
    "\n",
    "    output = K.layers.Concatenate()([\n",
    "        conv_1x1, conv_3x3, conv_5x5, conv_1x1_pooled\n",
    "    ])\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-main\n",
    "X = K.Input(shape=(224, 224, 3))\n",
    "Y = inception_block(X, [64, 96, 128, 16, 32, 32])\n",
    "model = K.models.Model(inputs=X, outputs=Y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1. Inception Network\n",
    "\"\"\"\n",
    "Write a function that builds the inception network as described in\n",
    "    `Going Deeper with Convolutions (2014)`\n",
    "\"\"\"\n",
    "def inception_network():\n",
    "    \"\"\"\n",
    "    Assume input data will have shape (224, 224, 3)\n",
    "    All convolutions inside and outside the inception block should use a ReLU\n",
    "    activation\n",
    "    Returns the Keras model\n",
    "    \"\"\"\n",
    "    inputs = K.Input(shape=(224, 224, 3))\n",
    "\n",
    "    conv_7x7_2s = K.layers.Conv2D(filters=64,\n",
    "                                 kernel_size=(7, 7),\n",
    "                                 strides=2,\n",
    "                                 padding='same',\n",
    "                                 activation='relu'\n",
    "                                 )(inputs)\n",
    "\n",
    "    MaxPool3x3_2s = K.layers.MaxPooling2D(pool_size=(3, 3),\n",
    "                                          strides=2,\n",
    "                                          padding='same'\n",
    "                                          )(conv_7x7_2s)\n",
    "\n",
    "    conv_1x1_1v = K.layers.Conv2D(filters=64,\n",
    "                                  kernel_size=(1, 1),\n",
    "                                  padding='valid',\n",
    "                                  activation='relu'\n",
    "                                  )(MaxPool3x3_2s)\n",
    "\n",
    "    conv_3x3_1s = K.layers.Conv2D(filters=192,\n",
    "                                  kernel_size=(3, 3),\n",
    "                                  strides=1,\n",
    "                                  padding='same',\n",
    "                                  activation='relu'\n",
    "                                  )(conv_1x1_1v)\n",
    "\n",
    "    MaxPool3x3_2s_1 = K.layers.MaxPooling2D(pool_size=(3, 3),\n",
    "                                            strides=2,\n",
    "                                            padding='same'\n",
    "                                            )(conv_3x3_1s)\n",
    "\n",
    "    inception_layer_0 = inception_block(MaxPool3x3_2s_1,\n",
    "                                        [64, 96, 128, 16, 32, 32])\n",
    "\n",
    "    inception_layer_1 = inception_block(inception_layer_0,\n",
    "                                        [128, 128, 192, 32, 96, 64])\n",
    "\n",
    "    MaxPool3x3_2s_2 = K.layers.MaxPooling2D(pool_size=(3, 3),\n",
    "                                            strides=2,\n",
    "                                            padding='same'\n",
    "                                            )(inception_layer_1)\n",
    "\n",
    "    inception_layer_2 = inception_block(MaxPool3x3_2s_2,\n",
    "                                        [192, 96, 208, 16, 48, 64])\n",
    "\n",
    "    inception_layer_3 = inception_block(inception_layer_2,\n",
    "                                        [160, 112, 224, 24, 64, 64])\n",
    "\n",
    "    inception_layer_4 = inception_block(inception_layer_3,\n",
    "                                        [128, 128, 256, 24, 64, 64])\n",
    "\n",
    "    inception_layer_5 = inception_block(inception_layer_4,\n",
    "                                        [112, 144, 288, 32, 64, 64])\n",
    "\n",
    "    inception_layer_6 = inception_block(inception_layer_5,\n",
    "                                        [256, 160, 320, 32, 128, 128])\n",
    "\n",
    "    MaxPool3x3_2s_3 = K.layers.MaxPooling2D(pool_size=(3, 3),\n",
    "                                            strides=2,\n",
    "                                            padding='same'\n",
    "                                            )(inception_layer_6)\n",
    "\n",
    "    inception_layer_7 = inception_block(MaxPool3x3_2s_3,\n",
    "                                        [256, 160, 320, 32, 128, 128])\n",
    "\n",
    "    inception_layer_8 = inception_block(inception_layer_7,\n",
    "                                        [384, 192, 384, 48, 128, 128])\n",
    "\n",
    "    AvgPool7x7_1v = K.layers.AveragePooling2D(pool_size=(7, 7),\n",
    "                                              strides=1,\n",
    "                                              padding='valid'\n",
    "                                              )(inception_layer_8)\n",
    "\n",
    "    dropout = K.layers.Dropout(.4)(AvgPool7x7_1v)\n",
    "\n",
    "    softmax = K.layers.Dense(units=1000,\n",
    "                             activation='softmax'\n",
    "                             )(dropout)\n",
    "\n",
    "    return K.Model(inputs=inputs, outputs=softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-main\n",
    "model = inception_network()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2. Identity Block\n",
    "\"\"\"\n",
    "Write a function that builds an identity block as described in\n",
    "    `Deep Residual Learning for Image Recognition(2015)`\n",
    "\"\"\"\n",
    "def identity_block(A_prev, filters):\n",
    "    \"\"\"\n",
    "    A_prev: output from the previous layer\n",
    "    filters: tuple or list containing F11, F3, F12 respectively\n",
    "        F11: number of filters in the first 1x1 convolution\n",
    "        F3: number of filters in the 3x3 convolution\n",
    "        F12: numnber of filters in the second 1x1 convolution\n",
    "    All convolutions inside the block should be followed by batch normalization\n",
    "        along the channels axis and a rectified linear activation (ReLU)\n",
    "    All weights should use he normal initialization\n",
    "    Returns the activated output of the identity block\n",
    "    \"\"\"\n",
    "    F11 = filters[0]\n",
    "    F3 = filters[1]\n",
    "    F12 = filters[2]\n",
    "\n",
    "    init = K.initializers.he_normal()\n",
    "\n",
    "    conv1x1_0 = K.layers.Conv2D(filters=F11,\n",
    "                                kernel_size=(1, 1),\n",
    "                                strides=1,\n",
    "                                padding='same',\n",
    "                                kernel_initializer=init\n",
    "                                )(A_prev)\n",
    "\n",
    "    batch_norm_0 = K.layers.BatchNormalization(axis=3)(conv1x1_0)\n",
    "\n",
    "    relu_0 = K.layers.ReLU()(batch_norm_0)\n",
    "\n",
    "    conv3x3_1 = K.layers.Conv2D(filters=F3,\n",
    "                                kernel_size=(3, 3),\n",
    "                                strides=1,\n",
    "                                padding='same',\n",
    "                                kernel_initializer=init)(relu_0)\n",
    "\n",
    "    batch_norm_1 = K.layers.BatchNormalization(axis=3)(conv3x3_1)\n",
    "\n",
    "    relu_1 = K.layers.ReLU()(batch_norm_1)\n",
    "\n",
    "    conv1x1_2 = K.layers.Conv2D(filters=F12,\n",
    "                                kernel_size=(1, 1),\n",
    "                                strides=1,\n",
    "                                padding='same',\n",
    "                                kernel_initializer=init)(relu_1)\n",
    "\n",
    "    batch_norm_2 = K.layers.BatchNormalization(axis=3)(conv1x1_2)\n",
    "\n",
    "    add_layer = K.layers.Add()([batch_norm_2, A_prev])\n",
    "\n",
    "    relu_output = K.layers.ReLU()(add_layer)\n",
    "\n",
    "    return relu_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-main\n",
    "X = K.Input(shape=(224, 224, 256))\n",
    "Y = identity_block(X, [64, 64, 256])\n",
    "model = K.models.Model(inputs=X, outputs=Y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3. Projection Block\n",
    "\"\"\"\n",
    "Write a function that builds an projection block as described in\n",
    "    `Deep Residual Learning for Image Recognition(2015)`\n",
    "\"\"\"\n",
    "def projection_block(A_prev, filters, s=2):\n",
    "    \"\"\"\n",
    "    A_prev: output from the previous layer\n",
    "    filters: tuple or list containing F11, F3, F12 respectively\n",
    "        F11: number of filters in the first 1x1 convolution\n",
    "        F3: number of filters in the 3x3 convolution\n",
    "        F12: numnber of filters in the second 1x1 convolution\n",
    "    s: stride for the first convolution in both the main path and the shortcut\n",
    "        connection\n",
    "    All convolutions inside the block should be followed by batch normalization\n",
    "        along the channels axis and a rectified linear activation (ReLU)\n",
    "    All weights should use he normal initialization\n",
    "    Returns the activated output of the identity block\n",
    "    \"\"\"\n",
    "    F11 = filters[0]\n",
    "    F3 = filters[1]\n",
    "    F12 = filters[2]\n",
    "\n",
    "    init = K.initializers.he_normal()\n",
    "\n",
    "    conv1x1_0 = K.layers.Conv2D(filters=F11,\n",
    "                                kernel_size=(1, 1),\n",
    "                                strides=s,\n",
    "                                padding='same',\n",
    "                                kernel_initializer=init\n",
    "                                )(A_prev)\n",
    "\n",
    "    batch_norm_0 = K.layers.BatchNormalization(axis=3)(conv1x1_0)\n",
    "\n",
    "    relu_0 = K.layers.ReLU()(batch_norm_0)\n",
    "\n",
    "    conv3x3_1 = K.layers.Conv2D(filters=F3,\n",
    "                                kernel_size=(3, 3),\n",
    "                                strides=1,\n",
    "                                padding='same',\n",
    "                                kernel_initializer=init)(relu_0)\n",
    "\n",
    "    batch_norm_1 = K.layers.BatchNormalization(axis=3)(conv3x3_1)\n",
    "\n",
    "    relu_1 = K.layers.ReLU()(batch_norm_1)\n",
    "\n",
    "    conv1x1_2 = K.layers.Conv2D(filters=F12,\n",
    "                                kernel_size=(1, 1),\n",
    "                                strides=1,\n",
    "                                padding='same',\n",
    "                                kernel_initializer=init)(relu_1)\n",
    "\n",
    "    batch_norm_2 = K.layers.BatchNormalization(axis=3)(conv1x1_2)\n",
    "\n",
    "    conv1x1_shortcut = K.layers.Conv2D(filters=F12,\n",
    "                                       kernel_size=(1, 1),\n",
    "                                       strides=s,\n",
    "                                       padding='same',\n",
    "                                       kernel_initializer=init)(A_prev)\n",
    "\n",
    "    batch_norm_shortcut = K.layers.BatchNormalization(axis=3)(conv1x1_shortcut)\n",
    "\n",
    "    add_layer = K.layers.Add()([batch_norm_2, batch_norm_shortcut])\n",
    "\n",
    "    relu_output = K.layers.ReLU()(add_layer)\n",
    "\n",
    "    return relu_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-main\n",
    "X = K.Input(shape=(224, 224, 3))\n",
    "Y = projection_block(X, [64, 64, 256])\n",
    "model = K.models.Model(inputs=X, outputs=Y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4. ResNet-50\n",
    "\"\"\"\n",
    "Write a function that builds the ResNet-50 architecture as described in\n",
    "    `Deep Residual Learning for Image Recognition (2015)`\n",
    "\"\"\"\n",
    "\n",
    "def resnet50():\n",
    "    \"\"\"\n",
    "    Assume input data will have shape (224, 224, 3)\n",
    "    All convolutions inside and outside the blocks should be followed by batch\n",
    "    normalization along the channels axis and a ReLU activation\n",
    "    All weights should use he normal initialization\n",
    "    Returns the keras model\n",
    "    \"\"\"\n",
    "    inputs = K.Input(shape=(224, 224, 3))\n",
    "    init = K.initializers.he_normal()\n",
    "\n",
    "    conv1 = K.layers.Conv2D(filters=64,\n",
    "                            kernel_size=(7, 7),\n",
    "                            strides=2,\n",
    "                            padding='same',\n",
    "                            kernel_initializer=init\n",
    "                            )(inputs)\n",
    "\n",
    "    batch_1 = K.layers.BatchNormalization(axis=3)(conv1)\n",
    "\n",
    "    ReLU_1 = K.layers.ReLU()(batch_1)\n",
    "\n",
    "    MaxPool1 = K.layers.MaxPooling2D(pool_size=(3, 3),\n",
    "                                     strides=2,\n",
    "                                     padding='same'\n",
    "                                     )(ReLU_1)\n",
    "\n",
    "    conv2_a = projection_block(MaxPool1, [64, 64, 256], s=1)\n",
    "    conv2_b = identity_block(conv2_a, [64, 64, 256])\n",
    "    conv2_c = identity_block(conv2_b, [64, 64, 256])\n",
    "\n",
    "    conv3_a = projection_block(conv2_c, [128, 128, 512])\n",
    "    conv3_b = identity_block(conv3_a, [128, 128, 512])\n",
    "    conv3_c = identity_block(conv3_b, [128, 128, 512])\n",
    "    conv3_d = identity_block(conv3_c, [128, 128, 512])\n",
    "\n",
    "    conv4_a = projection_block(conv3_d, [256, 256, 1024])\n",
    "    conv4_b = identity_block(conv4_a, [256, 256, 1024])\n",
    "    conv4_c = identity_block(conv4_b, [256, 256, 1024])\n",
    "    conv4_d = identity_block(conv4_c, [256, 256, 1024])\n",
    "    conv4_e = identity_block(conv4_d, [256, 256, 1024])\n",
    "    conv4_f = identity_block(conv4_e, [256, 256, 1024])\n",
    "\n",
    "    conv5_a = projection_block(conv4_f, [512, 512, 2048])\n",
    "    conv5_b = identity_block(conv5_a, [512, 512, 2048])\n",
    "    conv5_c = identity_block(conv5_b, [512, 512, 2048])\n",
    "\n",
    "    AvgPool = K.layers.AveragePooling2D(pool_size=(7, 7),\n",
    "                                        strides=1,\n",
    "                                        padding='valid'\n",
    "                                        )(conv5_c)\n",
    "\n",
    "    softmax = K.layers.Dense(units=1000,\n",
    "                             activation='softmax'\n",
    "                             )(AvgPool)\n",
    "\n",
    "    return K.Model(inputs=inputs, outputs=softmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-main\n",
    "model = resnet50()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5. Dense Block\n",
    "\"\"\"\n",
    "Write a function that builds a densse block as described in\n",
    "    `Densely Connectec Convolutional Networks`\n",
    "\"\"\"\n",
    "def dense_block(X, nb_filters, growth_rate, layers):\n",
    "    \"\"\"\n",
    "    X: output from the previous layer\n",
    "    nb_filters: integer representing the number of filters in X\n",
    "    growth_rate: growth rate for the dense block\n",
    "    layers: number of layers in the dense block\n",
    "    Use the bottleneck layers used for DenseNet-B\n",
    "    All weights should use the he normal initialization\n",
    "    Convolutions should be preceded by Batch Normalization & ReLU activation\n",
    "    Returns the concatenated output of each layer within the Dense Block and\n",
    "        the number of filters within the concatenated outputs, respectively\n",
    "    \"\"\"\n",
    "    init = K.initializers.he_normal()\n",
    "\n",
    "    concatenation = X\n",
    "    for layer in range(layers):\n",
    "        batch_norm_0 = K.layers.BatchNormalization(axis=3)(concatenation)\n",
    "        ReLU_0 = K.layers.ReLU()(batch_norm_0)\n",
    "        conv_0 = K.layers.Conv2D(filters=(4 * growth_rate),\n",
    "                                 kernel_size=(1, 1),\n",
    "                                 padding='same',\n",
    "                                 kernel_initializer=init\n",
    "                                 )(ReLU_0)\n",
    "        batch_norm_1 = K.layers.BatchNormalization(axis=3)(conv_0)\n",
    "        ReLU_1 = K.layers.ReLU()(batch_norm_1)\n",
    "        conv_1 = K.layers.Conv2D(filters=growth_rate,\n",
    "                                 kernel_size=(3, 3),\n",
    "                                 padding='same',\n",
    "                                 kernel_initializer=init\n",
    "                                 )(ReLU_1)\n",
    "        concatenation = K.layers.Concatenate()([concatenation, conv_1])\n",
    "        nb_filters = nb_filters + growth_rate\n",
    "\n",
    "    return (concatenation, nb_filters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_24 (InputLayer)          [(None, 56, 56, 64)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_677 (Batch  (None, 56, 56, 64)  256         ['input_24[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_519 (ReLU)               (None, 56, 56, 64)   0           ['batch_normalization_677[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_790 (Conv2D)            (None, 56, 56, 128)  8320        ['re_lu_519[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_678 (Batch  (None, 56, 56, 128)  512        ['conv2d_790[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_520 (ReLU)               (None, 56, 56, 128)  0           ['batch_normalization_678[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_791 (Conv2D)            (None, 56, 56, 32)   36896       ['re_lu_520[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_26 (Concatenate)   (None, 56, 56, 96)   0           ['input_24[0][0]',               \n",
      "                                                                  'conv2d_791[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_679 (Batch  (None, 56, 56, 96)  384         ['concatenate_26[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_521 (ReLU)               (None, 56, 56, 96)   0           ['batch_normalization_679[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_792 (Conv2D)            (None, 56, 56, 128)  12416       ['re_lu_521[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_680 (Batch  (None, 56, 56, 128)  512        ['conv2d_792[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_522 (ReLU)               (None, 56, 56, 128)  0           ['batch_normalization_680[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_793 (Conv2D)            (None, 56, 56, 32)   36896       ['re_lu_522[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_27 (Concatenate)   (None, 56, 56, 128)  0           ['concatenate_26[0][0]',         \n",
      "                                                                  'conv2d_793[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_681 (Batch  (None, 56, 56, 128)  512        ['concatenate_27[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_523 (ReLU)               (None, 56, 56, 128)  0           ['batch_normalization_681[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_794 (Conv2D)            (None, 56, 56, 128)  16512       ['re_lu_523[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_682 (Batch  (None, 56, 56, 128)  512        ['conv2d_794[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_524 (ReLU)               (None, 56, 56, 128)  0           ['batch_normalization_682[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_795 (Conv2D)            (None, 56, 56, 32)   36896       ['re_lu_524[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_28 (Concatenate)   (None, 56, 56, 160)  0           ['concatenate_27[0][0]',         \n",
      "                                                                  'conv2d_795[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_683 (Batch  (None, 56, 56, 160)  640        ['concatenate_28[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_525 (ReLU)               (None, 56, 56, 160)  0           ['batch_normalization_683[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_796 (Conv2D)            (None, 56, 56, 128)  20608       ['re_lu_525[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_684 (Batch  (None, 56, 56, 128)  512        ['conv2d_796[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_526 (ReLU)               (None, 56, 56, 128)  0           ['batch_normalization_684[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_797 (Conv2D)            (None, 56, 56, 32)   36896       ['re_lu_526[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_29 (Concatenate)   (None, 56, 56, 192)  0           ['concatenate_28[0][0]',         \n",
      "                                                                  'conv2d_797[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_685 (Batch  (None, 56, 56, 192)  768        ['concatenate_29[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_527 (ReLU)               (None, 56, 56, 192)  0           ['batch_normalization_685[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_798 (Conv2D)            (None, 56, 56, 128)  24704       ['re_lu_527[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_686 (Batch  (None, 56, 56, 128)  512        ['conv2d_798[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_528 (ReLU)               (None, 56, 56, 128)  0           ['batch_normalization_686[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_799 (Conv2D)            (None, 56, 56, 32)   36896       ['re_lu_528[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_30 (Concatenate)   (None, 56, 56, 224)  0           ['concatenate_29[0][0]',         \n",
      "                                                                  'conv2d_799[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_687 (Batch  (None, 56, 56, 224)  896        ['concatenate_30[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_529 (ReLU)               (None, 56, 56, 224)  0           ['batch_normalization_687[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_800 (Conv2D)            (None, 56, 56, 128)  28800       ['re_lu_529[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_688 (Batch  (None, 56, 56, 128)  512        ['conv2d_800[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_530 (ReLU)               (None, 56, 56, 128)  0           ['batch_normalization_688[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_801 (Conv2D)            (None, 56, 56, 32)   36896       ['re_lu_530[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_31 (Concatenate)   (None, 56, 56, 256)  0           ['concatenate_30[0][0]',         \n",
      "                                                                  'conv2d_801[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 339,264\n",
      "Trainable params: 336,000\n",
      "Non-trainable params: 3,264\n",
      "__________________________________________________________________________________________________\n",
      "256\n"
     ]
    }
   ],
   "source": [
    "# 5-main\n",
    "X = K.Input(shape=(56, 56, 64))\n",
    "Y, nb_filters = dense_block(X, 64, 32, 6)\n",
    "model = K.models.Model(inputs=X, outputs=Y)\n",
    "model.summary()\n",
    "print(nb_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 6. Transition Layer\n",
    "\"\"\"\n",
    "Write a function that builds a transition layer as described in \n",
    "    `Densely Connected Convolutional Networks`\n",
    "\"\"\"\n",
    "def transition_layer(X, nb_filters, compression):\n",
    "    \"\"\"\n",
    "    X: the output from the previous layer\n",
    "    nb_filters: integer representing the number of filters in X\n",
    "    compression: compression factor for the transition layer\n",
    "    Code should implement compression as used in DenseNet-C\n",
    "    All weights should use he normal initialization\n",
    "    All convolutions should be preceded by Batch Normalization and a ReLU\n",
    "    Returns the output of the transition layer an the number of filters within\n",
    "        the output, respectively\n",
    "    \"\"\"\n",
    "    init = K.initializers.he_normal()\n",
    "    filters = nb_filters * compression\n",
    "\n",
    "    batch_norm = K.layers.BatchNormalization(axis=3)(X)\n",
    "    ReLU = K.layers.ReLU()(batch_norm)\n",
    "    conv = K.layers.Conv2D(filters=filters,\n",
    "                           kernel_size=(1, 1),\n",
    "                           padding='same',\n",
    "                           kernel_initializer=init\n",
    "                           )(ReLU)\n",
    "    AvgPool = K.layers.AveragePooling2D(pool_size=(2, 2),\n",
    "                                        strides=2,\n",
    "                                        padding='same'\n",
    "                                        )(conv)\n",
    "\n",
    "    return (AvgPool, filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_25 (InputLayer)       [(None, 56, 56, 256)]     0         \n",
      "                                                                 \n",
      " batch_normalization_689 (Ba  (None, 56, 56, 256)      1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_531 (ReLU)            (None, 56, 56, 256)       0         \n",
      "                                                                 \n",
      " conv2d_802 (Conv2D)         (None, 56, 56, 128)       32896     \n",
      "                                                                 \n",
      " average_pooling2d_12 (Avera  (None, 28, 28, 128)      0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,920\n",
      "Trainable params: 33,408\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "128.0\n"
     ]
    }
   ],
   "source": [
    "# 6-main\n",
    "X = K.Input(shape=(56, 56, 256))\n",
    "Y, nb_filters = transition_layer(X, 256, 0.5)\n",
    "model = K.models.Model(inputs=X, outputs=Y)\n",
    "model.summary()\n",
    "print(nb_filters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
