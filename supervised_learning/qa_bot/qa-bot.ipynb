{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and tokenizer\n",
    "tokenizer_to_use = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "tokenizer = BertTokenizer.from_pretrained(tokenizer_to_use)\n",
    "model = hub.load(\"https://tfhub.dev/see--/bert-uncased-tf2-qa/1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_answer(question, reference):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        question: string containing the question to answer\n",
    "        reference: string containing the reference document to find answer\n",
    "    Returns:\n",
    "        String containing the answer or None if no answer is found\n",
    "    \"\"\"\n",
    "    quest_toks = tokenizer.tokenize(question)\n",
    "    ref_toks = tokenizer.tokenize(reference)\n",
    "    toks = ['[CLS]'] + quest_toks + ['[SEP]'] + ref_toks + ['[SEP]']\n",
    "    input_word_ids = tokenizer.convert_tokens_to_ids(toks)\n",
    "    input_mask = [1] * len(input_word_ids)\n",
    "    quest_len = len(quest_toks)\n",
    "    ref_len = len(ref_toks)\n",
    "    input_type_ids = [0] * (1 + quest_len + 1) + [1] * (ref_len + 1)\n",
    "\n",
    "    input_word_ids = tf.convert_to_tensor([input_word_ids])\n",
    "    input_mask = tf.convert_to_tensor([input_mask])\n",
    "    input_type_ids = tf.convert_to_tensor([input_type_ids])\n",
    "\n",
    "    outputs = model([input_word_ids, input_mask, input_type_ids])\n",
    "\n",
    "    short_start = tf.argmax(outputs[0][0][1:]) + 1\n",
    "    short_end = tf.argmax(outputs[1][0][1:]) + 1\n",
    "    answer_tokens = toks[short_start: short_end + 1]\n",
    "    answer = tokenizer.convert_tokens_to_string(answer_tokens)\n",
    "\n",
    "    if answer:\n",
    "        return answer\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When are PLDs?\n",
      "\ton - site days from 9 : 00 am to 3 : 00 pm\n",
      "What does PLD stand for?\n",
      "\tpeer learning days\n",
      "What are Mock Interviews?\n",
      "\tNone\n"
     ]
    }
   ],
   "source": [
    "# 0-main\n",
    "with open('ZendeskArticles/PeerLearningDays.md') as f:\n",
    "    reference = f.read()\n",
    "\n",
    "question = 'When are PLDs?'\n",
    "print(question + \"\\n\\t\" + str(question_answer(question, reference)))\n",
    "\n",
    "question = 'What does PLD stand for?'\n",
    "print(question + \"\\n\\t\" + str(question_answer(question, reference)))\n",
    "\n",
    "question = 'What are Mock Interviews?'\n",
    "print(question + \"\\n\\t\" + str(question_answer(question, reference)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Hello\n",
      "A: \n",
      "Q: How are you?\n",
      "A: \n",
      "Q: BYE\n",
      "A: Goodbye\n"
     ]
    }
   ],
   "source": [
    "exit_commands = ['exit', 'quit', 'goodbye', 'bye']\n",
    "while(True):\n",
    "    d = input('Q: ')\n",
    "    print(\"Q: \" + d)\n",
    "    if d.lower() in exit_commands:\n",
    "        print('A: Goodbye')\n",
    "        break\n",
    "    print(\"A: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_loop(reference):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        reference: the reference text\n",
    "    If the answer cannot be found in the reference text respond with:\n",
    "        'Sorry, I do not understand your question'\n",
    "    \"\"\"\n",
    "    exit_commands = ['exit', 'quit', 'goodbye', 'bye']\n",
    "    while(True):\n",
    "        question = input('Q: ')\n",
    "        print('Q: ' + question)\n",
    "        if question.lower() in exit_commands:\n",
    "            print('A: Goodbye')\n",
    "            break\n",
    "        answer = question_answer(question, reference)\n",
    "        if answer:\n",
    "            print('A: ' + answer)\n",
    "        else:\n",
    "            print('A: Sorry, I do not understand your question')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: When are PLDs?\n",
      "A: on - site days from 9 : 00 am to 3 : 00 pm\n",
      "Q: What are Mock Interviews?\n",
      "A: Sorry, I do not understand your question\n",
      "Q: What does PLD stand for?\n",
      "A: peer learning days\n",
      "Q: EXIT\n",
      "A: Goodbye\n"
     ]
    }
   ],
   "source": [
    "with open('ZendeskArticles/PeerLearningDays.md') as f:\n",
    "    reference = f.read()\n",
    "\n",
    "answer_loop(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(corpus_path, sentence):\n",
    "    \"\"\"\n",
    "    Performs semantic search on a corpus of documents\n",
    "    Args:\n",
    "        corpus_path: path to the corpus of reference documents\n",
    "        sentence: sentence on which to perform semantic search\n",
    "    Returns:\n",
    "        reference text of the document most similar to sentence\n",
    "    \"\"\"\n",
    "    # Convert document text into list\n",
    "    corpus = []\n",
    "    for item in os.listdir(corpus_path):\n",
    "        with open(os.path.join(corpus_path, item), 'r') as f:\n",
    "            text = f.read()\n",
    "            corpus.append(text)\n",
    "    print(corpus[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computer and Internet Usage Policy\n",
      "There is to be no video game play at school before 6:00 PM on weekdays\n",
      "The intranet is proprietary. Screenshots and copies of projects/assignments are strictly prohibited from being shared. (Please refer to the Intellectual Property - Ownership Policy in the Student Catalog);\n",
      "Holberton communications (Slack messages, emails, Holberton produced slide decks, etc.) are considered confidential communications and are not permitted to be shared publicly. (Please refer to the Intellectual Property - Ownership Policy in the Student Catalog);\n",
      "It is required to regularly check your Holberton accounts:\n",
      "Messages via the intranet on a daily basis\n",
      "Slack Messages\n",
      "Emails in your Google account on a daily basis\n",
      "We have a zero tolerance policy for torrenting illegal data. Torrenting at school could result in immediate dismissal.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(semantic_search('ZendeskArticles', 'When are PLDs?'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
