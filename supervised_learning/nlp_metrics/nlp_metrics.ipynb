{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 0. Unigram BLEU score\n",
    "def uni_bleu(references, sentence):\n",
    "    \"\"\"\n",
    "    Calculates the unigram BLEU score for a sentence.\n",
    "\n",
    "    Args:\n",
    "        references: list of reference translations\n",
    "            - Each reference translataion is a list of the words in the\n",
    "              translation\n",
    "        sentence: list containing the model proposed sentence\n",
    "\n",
    "    Returns:\n",
    "        the unigram BLEU score\n",
    "\n",
    "    My Notes:\n",
    "        The final output is the brevity penalty multiplied by the number of\n",
    "        words from our machine translated sentence show up in our references\n",
    "        divided by the number of words in the machine translated sentence\n",
    "\n",
    "        Example:\n",
    "            machine_translation: \"there is a cat here\"\n",
    "            ref1: \"the cat is on the mat\"\n",
    "            ref2: \"there is a cat on the mat\"\n",
    "\n",
    "        brevity penalty if candidate is shorter than any reference, else 1:\n",
    "            e^(1-r/c)\n",
    "            r: length of reference sentence that is closest to length of\n",
    "                machine translated sentence\n",
    "            c: length of machine translated sentence\n",
    "\n",
    "        In our candidate: [there, is, a cat] are all in our references = 4\n",
    "        Candidate is 5 long\n",
    "\n",
    "        We finally end up with (4/5) * (e^(1-(6/5)))\n",
    "    \"\"\"\n",
    "    # Calculate the first number, P = m/w_t\n",
    "    # m = number of words from sentence in references\n",
    "    # w_t = number of words in translated sentence\n",
    "    w_t = len(sentence)\n",
    "    m = 0\n",
    "    corpus = []\n",
    "\n",
    "    for reference in references:\n",
    "        for word in sentence:\n",
    "            if word in reference and word not in corpus:\n",
    "                corpus.append(word)\n",
    "\n",
    "    m = len(corpus)\n",
    "    P = m / w_t\n",
    "\n",
    "    ref_len = min(len(reference) for reference in references)\n",
    "\n",
    "    BP = min(1, np.exp(1-(ref_len/w_t)))\n",
    "\n",
    "    return P * BP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6549846024623855\n"
     ]
    }
   ],
   "source": [
    "# 0-main\n",
    "references = [[\"the\", \"cat\", \"is\", \"on\", \"the\", \"mat\"], [\"there\", \"is\", \"a\", \"cat\", \"on\", \"the\", \"mat\"]]\n",
    "sentence = [\"there\", \"is\", \"a\", \"cat\", \"here\"]\n",
    "\n",
    "print(uni_bleu(references, sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1. N-gram BLEU score\n",
    "def ngram_bleu(references, sentence, n):\n",
    "    \"\"\"\n",
    "    Calculates the n-gram BLEU score for a sentence\n",
    "\n",
    "    Args:\n",
    "        references: list of reference translations\n",
    "            - Each reference translataion is a list of the words in the\n",
    "              translation\n",
    "        sentence: list containing the model proposed sentence\n",
    "        n: size of the n-gram to use for evaluation\n",
    "\n",
    "    Returns:\n",
    "        the unigram BLEU score\n",
    "\n",
    "    Notes:\n",
    "        Similar to unigram, except need to make a dictionaries of tuples to\n",
    "        find matches.\n",
    "    \"\"\"\n",
    "    # Calculate n-gram counts in the sentence (Create corpus of tuples)\n",
    "    corpus = {}\n",
    "    for i in range(len(sentence) - n + 1):\n",
    "        ngram = tuple(sentence[i:i + n])\n",
    "        corpus[ngram] = corpus.get(ngram, 0) + 1\n",
    "    print(\"Corpus:\", corpus)\n",
    "    w_t = len(corpus)\n",
    "\n",
    "    # Calculate maximum n-gram counts in the references\n",
    "    max_counts = {}\n",
    "    for reference in references:\n",
    "        ref_counts = {}\n",
    "        for i in range(len(reference) - n + 1):\n",
    "            ngram = tuple(reference[i:i + n])\n",
    "            ref_counts[ngram] = ref_counts.get(ngram, 0) + 1\n",
    "        for ngram, count in ref_counts.items():\n",
    "            max_counts[ngram] = max(max_counts.get(ngram, 0), count)\n",
    "    print(\"Max Counts:\", max_counts)\n",
    "    print(\"Length Max Counts:\", len(max_counts))\n",
    "\n",
    "    # Calculate clipped n-gram counts\n",
    "    clipped_counts = {}\n",
    "    for ngram, count in corpus.items():\n",
    "        clipped_counts[ngram] = min(count, max_counts.get(ngram, 0))\n",
    "    print(\"Clipped counts: \", clipped_counts)\n",
    "    print(\"Clipped Conts Length:\", len(clipped_counts))\n",
    "\n",
    "    m = sum(clipped_counts.values())\n",
    "\n",
    "    print(\"m:\", m)\n",
    "\n",
    "    P = m / w_t\n",
    "    print(\"P:\",P)\n",
    "\n",
    "    # Calculate brevity penalty\n",
    "    ref_len = min(len(reference) for reference in references)\n",
    "    c = len(sentence)\n",
    "    BP = min(1, np.exp(1 - ref_len / c))\n",
    "\n",
    "    from nltk.translate.bleu_score import sentence_bleu\n",
    "    library_n_gram = (sentence_bleu(references, sentence, weights=(0, 1, 0, 0)))\n",
    "    print(\"Library n-gram calculation: \", library_n_gram)\n",
    "\n",
    "    return P * BP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus: {('there', 'is'): 1, ('is', 'a'): 1, ('a', 'cat'): 1, ('cat', 'here'): 1}\n",
      "Max Counts: {('the', 'cat'): 1, ('cat', 'is'): 1, ('is', 'on'): 1, ('on', 'the'): 1, ('the', 'mat'): 1, ('there', 'is'): 1, ('is', 'a'): 1, ('a', 'cat'): 1, ('cat', 'on'): 1}\n",
      "Length Max Counts: 9\n",
      "Clipped counts:  {('there', 'is'): 1, ('is', 'a'): 1, ('a', 'cat'): 1, ('cat', 'here'): 0}\n",
      "Clipped Conts Length: 4\n",
      "m: 3\n",
      "P: 0.75\n",
      "Library n-gram calculation:  0.6140480648084865\n",
      "0.6140480648084865\n"
     ]
    }
   ],
   "source": [
    "# 1-main\n",
    "references = [[\"the\", \"cat\", \"is\", \"on\", \"the\", \"mat\"], [\"there\", \"is\", \"a\", \"cat\", \"on\", \"the\", \"mat\"]]\n",
    "sentence = [\"there\", \"is\", \"a\", \"cat\", \"here\"]\n",
    "\n",
    "print(ngram_bleu(references, sentence, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
