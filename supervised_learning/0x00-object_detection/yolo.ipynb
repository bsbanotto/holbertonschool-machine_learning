{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 12:33:30.793483: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-21 12:33:30.981078: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-21 12:33:30.981144: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import tensorflow.keras as K\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO Class\n",
    "# Task 1. Process Outputs\n",
    "class Yolo:\n",
    "    \"\"\"\n",
    "    Initialize Yolo class.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_path, classes_path, class_t, nms_t, anchors):\n",
    "        \"\"\"\n",
    "        Class Constructor\n",
    "        model_path: path to where Darnket Keras model is stored\n",
    "        classes_path: path to list of class names used for Darknet model\n",
    "        class_t: float representing box score threshold for initial filtering\n",
    "        nms_t: float representing the IOU threshold for non-max suppression\n",
    "        anchors: numpy.ndarray of shape (outputs, anchor_boxes, 2) containing\n",
    "        the anchor boxes\n",
    "            outputs: number of outputs made by the Darknet model\n",
    "            anchor_boxes: number of anchor boxes used for each prediction\n",
    "            2: [anchor_box_width, anchor_box_height]\n",
    "        \n",
    "        Public Instance Attributes\n",
    "            model: Darknet Keras Model\n",
    "            class_names: list of the class names for the model\n",
    "            class_t: box score threshold for initial filtering\n",
    "            nms_t: IOU threshold for non-max suppression\n",
    "            anchors: the anchor boxes\n",
    "        \"\"\"\n",
    "        self.model = K.models.load_model(model_path)\n",
    "        with open(classes_path) as file:\n",
    "            class_names = file.read()\n",
    "        self.class_names = class_names.replace(\"\\n\", \"|\").split(\"|\")[:-1]\n",
    "        self.class_t = class_t\n",
    "        self.nms_t = nms_t\n",
    "        self.anchors = anchors\n",
    "\n",
    "    def process_outputs(self, outputs, image_size):\n",
    "        \"\"\"\n",
    "        Process outputs of Darknet model\n",
    "        outputs: numpy.ndarray containing predictions for a single image\n",
    "            Each output will have the shape (grid_height,\n",
    "                                             grid_width,\n",
    "                                             anchor_boxes,\n",
    "                                             4 + 1 + classes)\n",
    "                grid_height: height of grid used for output\n",
    "                grid_width: width of grid used for output\n",
    "                anchor_boxes: number of anchor boxes used\n",
    "                4: label_center[t_x, t_y], label_width[t_w], label_height[t_h]\n",
    "                1: box confidence\n",
    "                classes: class probabilities for all classes\n",
    "        image_size: numpy.ndarray containing the original image size\n",
    "            [image_height, image_width]\n",
    "\n",
    "        Returns a tuple of (boxes, box_confidences, box_class_probs)\n",
    "            boxes: list of numpy.ndarrays of shape (grid_height,\n",
    "                                                    grid_width,\n",
    "                                                    anchor_boxes,\n",
    "                                                    4)\n",
    "                4: x1, y1, x2, y2\n",
    "                    (top_left[x1, y1], bot_right[x2, y2]) should represent the\n",
    "                    boundary box relative to original image\n",
    "            box_confidences: a list of numpy.ndarrays of shape (grid_height,\n",
    "                                                                grid_width,\n",
    "                                                                anchor_boxes,\n",
    "                                                                classes)\n",
    "                containing the confidences for each output, respectively\n",
    "            box_class_probs: list of numpy.ndarrays of shape (grid_height,\n",
    "                                                              grid_width,\n",
    "                                                              anchor_boxes,\n",
    "                                                              classes)\n",
    "                containing the box's class probabilities for each output\n",
    "        \"\"\"\n",
    "        # Create lists for return\n",
    "        box_confidences, box_class_probs = [], []\n",
    "        boxes = [output[..., :4] for output in outputs]\n",
    "\n",
    "        # Create lists for bounding box corner coordinates\n",
    "        x_corners, y_corners = [], []\n",
    "\n",
    "        # Define sigmoid activation function\n",
    "        def sigmoid(z):\n",
    "            \"\"\"\n",
    "            sigmoid activation function\n",
    "            \"\"\"\n",
    "            return (1 / (1 + np.exp(-z)))\n",
    "\n",
    "        # Create all of the grid cells to overlay image\n",
    "        # Calculate box_confidences and box_class_probs\n",
    "        for output in outputs:\n",
    "            grid_height = output.shape[0]\n",
    "            grid_width = output.shape[1]\n",
    "            anchors = output.shape[2]\n",
    "\n",
    "            cx = np.arange(grid_width).reshape(1, grid_width)\n",
    "            cx = np.repeat(cx, grid_height, axis=0)\n",
    "            x_corners.append(np.repeat(cx[..., np.newaxis], anchors, axis=2))\n",
    "            cy = np.arange(grid_width).reshape(1, grid_width)\n",
    "            cy = np.repeat(cy, grid_height, axis=0).T\n",
    "            y_corners.append(np.repeat(cy[..., np.newaxis], anchors, axis=2))\n",
    "\n",
    "            box_confidences.append(sigmoid(output[..., 4:5]))\n",
    "            box_class_probs.append(sigmoid(output[..., 5:]))\n",
    "\n",
    "        input_width = self.model.input.shape[1]\n",
    "        input_height = self.model.input.shape[2]\n",
    "\n",
    "        for x, box in enumerate(boxes):\n",
    "            # Activate bounding boxes\n",
    "            bx = (sigmoid(box[..., 0]) + x_corners[x])/outputs[x].shape[1]\n",
    "            by = (sigmoid(box[..., 1]) + y_corners[x])/outputs[x].shape[0]\n",
    "            bw = (np.exp(box[..., 2]) * self.anchors[x, :, 0]) / input_width\n",
    "            bh = (np.exp(box[..., 3]) * self.anchors[x, :, 1]) / input_height\n",
    "\n",
    "            # Move bounding box coordinates from center to corner\n",
    "            box[..., 0] = (bx - (bw * .5)) * image_size[1]\n",
    "            box[..., 1] = (by - (bh * .5)) * image_size[0]\n",
    "            box[..., 2] = (bx + (bw * .5)) * image_size[1]\n",
    "            box[..., 3] = (by + (bh * .5)) * image_size[0]\n",
    "\n",
    "\n",
    "        return (boxes, box_confidences, box_class_probs)\n",
    "\n",
    "    def filter_boxes(self, boxes, box_confidences, box_class_probs):\n",
    "        \"\"\"\n",
    "        Determine which bounding boxes meet or exceed threshold\n",
    "        boxes: list of numpy.ndarrays of shape (grid_height,\n",
    "                                                grid_width,\n",
    "                                                anchor_boxes,\n",
    "                                                4)\n",
    "            containing the processed boundary boxes for each output\n",
    "        box_confidences: list of numpy.ndarrays of shape (grid_height,\n",
    "                                                          grid_width,\n",
    "                                                          anchor_boxes,\n",
    "                                                          1)\n",
    "            containing the processed box confidences for each output\n",
    "        box_class_probs: list of numpy.ndarrays of shape (grid_height,\n",
    "                                                          grid_width,\n",
    "                                                          anchor_boxes,\n",
    "                                                          classes)\n",
    "            containing the preprocessed box class probabilities for each output\n",
    "\n",
    "        Returns a tuple of (filtered_boxes, box_classes, box_scores)\n",
    "            filtered_boxes: numpy.ndarray of shape (?, 4) containing all of the\n",
    "                filtered bounding boxes\n",
    "            box_classes: numpy.ndarray of shape (?,) containing the class\n",
    "                number that each box in filtered_boxes predicts\n",
    "            box_scores: numpy.ndarray of shape (?) containing the box scores\n",
    "                for each box in filtered_boxes\n",
    "        \"\"\"\n",
    "        # Create items for return tuple\n",
    "        filtered_boxes, box_classes, box_scores = None, [], []\n",
    "\n",
    "        for box in range(len(boxes)):\n",
    "            score = np.max(box_class_probs[box] * box_confidences[box],\n",
    "                           axis=3)\n",
    "            cls = np.argmax(box_class_probs[box] * box_confidences[box],\n",
    "                            axis=3)\n",
    "            index = score >= self.class_t\n",
    "\n",
    "            if filtered_boxes is None:\n",
    "                filtered_boxes = boxes[box][index]\n",
    "            else:\n",
    "                filtered_boxes = np.concatenate((filtered_boxes,\n",
    "                                                 boxes[box][index]),\n",
    "                                                 axis=0)\n",
    "            filtered_score = score[index]\n",
    "            filtered_cls = cls[index]\n",
    "\n",
    "            box_classes = np.concatenate((box_classes, filtered_cls), axis=0)\n",
    "            box_scores = np.concatenate((box_scores, filtered_score), axis=0)\n",
    "\n",
    "\n",
    "        return (filtered_boxes, box_classes.astype(int), box_scores)\n",
    "\n",
    "    def _iou(self, box1, box2):\n",
    "        \"\"\"Calculates IoU for two boxes\"\"\"\n",
    "        x1 = max(box1[0], box2[0])\n",
    "        y1 = max(box1[1], box2[1])\n",
    "        x2 = min(box1[2], box2[2])\n",
    "        y2 = min(box1[3], box2[3])\n",
    "\n",
    "        intersection_area = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "        box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "        box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "\n",
    "        union_area = box1_area + box2_area - intersection_area\n",
    "        return intersection_area / union_area\n",
    "\n",
    "    def non_max_suppression(self, filtered_boxes, box_classes, box_scores):\n",
    "        \"\"\"\n",
    "        Method to suppress all non-max bounding boxes in each grid square\n",
    "        filtered_boxes: numpy.ndarray of shape (?, 4) containing all of the\n",
    "            filtered bounding boxes\n",
    "        box_classes: numpy.ndarray of shape (?,) containing the class number\n",
    "            for the class that filtered_boxes predicts\n",
    "        box_scores: numpy.ndarray of shape (?) containing the box scores for\n",
    "            each box in filtered_boxes\n",
    "        Returns a tuple of (box_predictions, predicted_box_classes,\n",
    "            predicted_box_scores):\n",
    "            box_predictions: numpy.ndarray shape (?, 4) containing all of the\n",
    "                predicted bounding boxes ordered by class and box score\n",
    "            predicted_box_classes: numpy.ndarray shape (?,) containing the\n",
    "                class number for box_predictions ordered by class and box score\n",
    "            predicted_box_scores: numpy.ndarray shape (?) containing the box\n",
    "                scores for box_predictions ordered by class and box score\n",
    "        \"\"\"\n",
    "        unique_classes = np.unique(box_classes)\n",
    "        box_predictions = []\n",
    "        predicted_box_classes = []\n",
    "        predicted_box_scores = []\n",
    "\n",
    "        for cls in unique_classes:\n",
    "            idxs = np.where(box_classes == cls)\n",
    "            cls_boxes = filtered_boxes[idxs]\n",
    "            cls_box_scores = box_scores[idxs]\n",
    "\n",
    "            while len(cls_boxes) > 0:\n",
    "                max_score_idx = np.argmax(cls_box_scores)\n",
    "                box_predictions.append(cls_boxes[max_score_idx])\n",
    "                predicted_box_classes.append(cls)\n",
    "                predicted_box_scores.append(cls_box_scores[max_score_idx])\n",
    "\n",
    "                iou_scores = [self._iou(cls_boxes[max_score_idx],\n",
    "                                        box) for box in cls_boxes]\n",
    "                to_remove = np.where(np.array(iou_scores) >= self.nms_t)\n",
    "                cls_boxes = np.delete(cls_boxes, to_remove, axis=0)\n",
    "                cls_box_scores = np.delete(cls_box_scores, to_remove, axis=0)\n",
    "\n",
    "        return (np.array(box_predictions),\n",
    "                np.array(predicted_box_classes),\n",
    "                np.array(predicted_box_scores))\n",
    "\n",
    "    @staticmethod\n",
    "    def load_images(folder_path):\n",
    "        \"\"\"\n",
    "        Method to load images given a folder path\n",
    "        Returns a tuple of (images, image_paths)\n",
    "        \"\"\"\n",
    "        images = []\n",
    "        image_paths = []\n",
    "        for photo in os.listdir(folder_path):\n",
    "            images.append(cv2.imread(folder_path + '/' + photo))\n",
    "            image_paths.append(folder_path + '/' + photo)\n",
    "        return (images, image_paths)\n",
    "\n",
    "    def preprocess_images(self, images):\n",
    "        \"\"\"\n",
    "        images: list of images as numpy.ndarrays\n",
    "        Resize image with inter-cubic interpolation\n",
    "        Rescale all images to have pixel values in range [0, 1]\n",
    "        Returns a tuple of (pimages, image_shape)\n",
    "            pimages: numpy.ndarray of shape (ni, input_h, input_w, 3)\n",
    "                ni: number of images that were preprocessed\n",
    "                input_h: input height for the Darknet model\n",
    "                input_w: input width fot the Darknet model\n",
    "                3: number of color channels\n",
    "            image_shapes: numpy.ndarray of shape (ni, 2) containing the\n",
    "                original height and width of the images\n",
    "                    2: (image_height, image_width)\n",
    "        \"\"\"\n",
    "        pimages, image_shapes = [], []\n",
    "        processed_size = (self.model.input.shape[1],\n",
    "                          self.model.input.shape[2])\n",
    "        for image in images:\n",
    "            pimages.append((cv2.resize(image,\n",
    "                            processed_size,\n",
    "                            interpolation=cv2.INTER_CUBIC)) / 255)\n",
    "            image_shapes.append(image.shape[0:2])\n",
    "\n",
    "        pimages = np.asarray(pimages)\n",
    "        image_shapes = np.asarray(image_shapes)\n",
    "        return (pimages, image_shapes)\n",
    "\n",
    "    def show_boxes(self, image, boxes, box_classes, box_scores, file_name):\n",
    "        \"\"\"\n",
    "        image: numpy.ndarray containing an unprocessed image\n",
    "        boxes: numpy.ndarray containing the boundary boxes for the image\n",
    "        box_classes: numpy.ndarray containing the class indices for each box\n",
    "        box_scores: numpy.ndarray containing the box scores for each box\n",
    "        file_name: path to where the original image is stored\n",
    "        Displays the image with all boundary boxes, class names, and box scores\n",
    "            Boxes should be drawn witha  blue line of thickness 2\n",
    "            Class names and box scores should be drawn above each box in red\n",
    "                Round box scores to 2 decimal places\n",
    "                Text should be written 5 pixels above the top left corner\n",
    "                Text should be written in FONT_HERSHEY_SIMPLEX\n",
    "                Font scale should be 0.5\n",
    "                Line thickness should be 1\n",
    "                Use LINE_AA as the line type\n",
    "            The window name should be the same as file_name\n",
    "            If the `s` key is pressed:\n",
    "                The image should be saved in the directory `detections` located\n",
    "                    in the current directory\n",
    "                If `detections` does not exist, create it\n",
    "                The saved image should have the name file_name\n",
    "                The image window should be closed\n",
    "        \"\"\"\n",
    "        for i, box in enumerate(boxes):\n",
    "            pt1 = (int(box[0]), int(box[1]))\n",
    "            pt2 = (int(box[2]), int(box[3]))\n",
    "            label_title = self.class_names[box_classes[i]]\n",
    "            label_score = box_scores[i]\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            offset = (int(box[0]), int(box[1] - 5))\n",
    "            blue = (255, 0, 0)\n",
    "            red = (0, 0, 255)\n",
    "            cv2.rectangle(image, pt1, pt2, blue, 2)\n",
    "            label = \"{} {:.2f}\".format(label_title, label_score)\n",
    "            cv2.putText(image, label, offset, font, 0.5, red, 1, cv2.LINE_AA)\n",
    "        cv2.imshow(file_name, image)\n",
    "        key = cv2.waitKey(0)\n",
    "\n",
    "        if key == ord('s'):\n",
    "            if not os.path.exists('detections'):\n",
    "                os.makedirs('detections')\n",
    "            cv2.imwrite(os.path.join('detections', file_name), image)\n",
    "\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def predict(self, folder_path):\n",
    "        \"\"\"\n",
    "        Detects objects in photos located in folder_path\n",
    "        Returns a tuple of (predictions, image_paths)\n",
    "            predictions: list of tuples for each image of\n",
    "                (boxes, box_classes, box_scores)\n",
    "            image_paths: list of image paths corresponding to each prediction\n",
    "                in predictions\n",
    "        \"\"\"\n",
    "        images, paths = self.load_images(folder_path)\n",
    "        pimages, pimage_shapes = self.preprocess_images(images)\n",
    "        darknet_pred_set = self.model.predict(pimages)\n",
    "        predictions = []\n",
    "\n",
    "        # darknet outputs 3 predictions. Need to look at each\n",
    "        for x, img in enumerate(images):\n",
    "            darknet_pred = [\n",
    "                darknet_pred_set[0][x, ...],\n",
    "                darknet_pred_set[1][x, ...],\n",
    "                darknet_pred_set[2][x, ...]\n",
    "            ]\n",
    "\n",
    "            boxes, box_confidences, box_class_probs = self.process_outputs(\n",
    "                darknet_pred, pimage_shapes[x]\n",
    "            )\n",
    "            filtered_boxes, box_classes, box_scores = self.filter_boxes(\n",
    "                boxes, box_confidences, box_class_probs\n",
    "            )\n",
    "            box_pred, pred_classes, pred_scores = self.non_max_suppression(\n",
    "                filtered_boxes, box_classes, box_scores\n",
    "            )\n",
    "            predictions.append((box_pred, pred_classes, pred_scores))\n",
    "\n",
    "            self.show_boxes(img,\n",
    "                            box_pred,\n",
    "                            pred_classes,\n",
    "                            pred_scores,\n",
    "                            paths[x].split('/')[-1])\n",
    "\n",
    "            # Ignore Non-Max-Suppression\n",
    "            # self.show_boxes(img,\n",
    "            #                 filtered_boxes,\n",
    "            #                 box_classes,\n",
    "            #                 box_scores,\n",
    "            #                 paths[x].split('/')[-1])\n",
    "\n",
    "        return (predictions, paths)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-main\n",
    "np.random.seed(0)\n",
    "anchors = np.array([[[116, 90], [156, 198], [373, 326]],\n",
    "                    [[30, 61], [62, 45], [59, 119]],\n",
    "                    [[10, 13], [16, 30], [33, 23]]])\n",
    "yolo = Yolo('../data/yolo.h5', '../data/coco_classes.txt', 0.6, 0.5, anchors)\n",
    "yolo.model.summary()\n",
    "print('Class names:', yolo.class_names)\n",
    "print('Class threshold:', yolo.class_t)\n",
    "print('NMS threshold:', yolo.nms_t)\n",
    "print('Anchor boxes:', yolo.anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-main\n",
    "np.random.seed(0)\n",
    "anchors = np.array([[[116, 90], [156, 198], [373, 326]],\n",
    "                    [[30, 61], [62, 45], [59, 119]],\n",
    "                    [[10, 13], [16, 30], [33, 23]]])\n",
    "yolo = Yolo('../data/yolo.h5', '../data/coco_classes.txt', 0.6, 0.5, anchors)\n",
    "output1 = np.random.randn(13, 13, 3, 85)\n",
    "output2 = np.random.randn(26, 26, 3, 85)\n",
    "output3 = np.random.randn(52, 52, 3, 85)\n",
    "boxes, box_confidences, box_class_probs = yolo.process_outputs([output1, output2, output3], np.array([500, 700]))\n",
    "print('Boxes:', boxes)\n",
    "print('Box confidences:', box_confidences)\n",
    "print('Box class probabilities:', box_class_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-main\n",
    "np.random.seed(0)\n",
    "anchors = np.array([[[116, 90], [156, 198], [373, 326]],\n",
    "                    [[30, 61], [62, 45], [59, 119]],\n",
    "                    [[10, 13], [16, 30], [33, 23]]])\n",
    "yolo = Yolo('../data/yolo.h5', '../data/coco_classes.txt', 0.6, 0.5, anchors)\n",
    "output1 = np.random.randn(13, 13, 3, 85)\n",
    "output2 = np.random.randn(26, 26, 3, 85)\n",
    "output3 = np.random.randn(52, 52, 3, 85)\n",
    "boxes, box_confidences, box_class_probs = yolo.process_outputs([output1, output2, output3], np.array([500, 700]))\n",
    "boxes, box_classes, box_scores = yolo.filter_boxes(boxes, box_confidences, box_class_probs)\n",
    "print('Boxes:', boxes)\n",
    "print('Box classes:', box_classes)\n",
    "print('Box scores:', box_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-main\n",
    "np.random.seed(0)\n",
    "anchors = np.array([[[116, 90], [156, 198], [373, 326]],\n",
    "                    [[30, 61], [62, 45], [59, 119]],\n",
    "                    [[10, 13], [16, 30], [33, 23]]])\n",
    "yolo = Yolo('../data/yolo.h5', '../data/coco_classes.txt', 0.6, 0.5, anchors)\n",
    "output1 = np.random.randn(13, 13, 3, 85)\n",
    "output2 = np.random.randn(26, 26, 3, 85)\n",
    "output3 = np.random.randn(52, 52, 3, 85)\n",
    "boxes, box_confidences, box_class_probs = yolo.process_outputs([output1, output2, output3], np.array([500, 700]))\n",
    "boxes, box_classes, box_scores = yolo.filter_boxes(boxes, box_confidences, box_class_probs)\n",
    "boxes, box_classes, box_scores = yolo.non_max_suppression(boxes, box_classes, box_scores)\n",
    "print('Boxes:', boxes)\n",
    "print('Box classes:', box_classes)\n",
    "print('Box scores:', box_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-main\n",
    "np.random.seed(0)\n",
    "anchors = np.array([[[116, 90], [156, 198], [373, 326]],\n",
    "                    [[30, 61], [62, 45], [59, 119]],\n",
    "                    [[10, 13], [16, 30], [33, 23]]])\n",
    "yolo = Yolo('../data/yolo.h5', '../data/coco_classes.txt', 0.6, 0.5, anchors)\n",
    "images, image_paths = yolo.load_images('../data/yolo')\n",
    "i = np.random.randint(0, len(images))\n",
    "cv2.imshow(image_paths[i], images[i])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-main\n",
    "np.random.seed(3)\n",
    "anchors = np.array([[[116, 90], [156, 198], [373, 326]],\n",
    "                    [[30, 61], [62, 45], [59, 119]],\n",
    "                    [[10, 13], [16, 30], [33, 23]]])\n",
    "yolo = Yolo('../data/yolo.h5', '../data/coco_classes.txt', 0.6, 0.5, anchors)\n",
    "images, image_paths = yolo.load_images('../data/yolo')\n",
    "pimages, image_shapes = yolo.preprocess_images(images)\n",
    "print(type(pimages), pimages.shape)\n",
    "print(type(image_shapes), image_shapes.shape)\n",
    "i = np.random.randint(0, len(images))\n",
    "print(images[i].shape, ':', image_shapes[i])\n",
    "cv2.imshow(image_paths[i], pimages[i])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6-main\n",
    "np.random.seed(0)\n",
    "anchors = np.array([[[116, 90], [156, 198], [373, 326]],\n",
    "                    [[30, 61], [62, 45], [59, 119]],\n",
    "                    [[10, 13], [16, 30], [33, 23]]])\n",
    "yolo = Yolo('../data/yolo.h5', '../data/coco_classes.txt', 0.6, 0.5, anchors)\n",
    "images, image_paths = yolo.load_images('../data/yolo')\n",
    "boxes = np.array([[119.22100287, 118.62197718, 567.75985556, 440.44121152],\n",
    "                    [468.53530752, 84.48338278, 696.04923556, 167.98947829],\n",
    "                    [124.2043716, 220.43365057, 319.4254314 , 542.13706101]])\n",
    "box_scores = np.array([0.99537075, 0.91536146, 0.9988506])\n",
    "box_classes = np.array([1, 7, 16])\n",
    "ind = 0\n",
    "for i, name in enumerate(image_paths):\n",
    "    if \"dog.jpg\" in name: \n",
    "        ind = i\n",
    "        break\n",
    "yolo.show_boxes(images[i], boxes, box_classes, box_scores, \"dog.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 12:34:18.451692: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/bsbanotto/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-04-21 12:34:18.451770: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-04-21 12:34:18.451882: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (BensLaptop): /proc/driver/nvidia/version does not exist\n",
      "2023-04-21 12:34:18.453124: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "../data/yolo/dog.jpg\n",
      "(array([[119.10174, 118.63829, 567.89417, 440.58704],\n",
      "       [468.6808 ,  84.4819 , 695.9741 , 168.00749],\n",
      "       [124.10596, 220.4373 , 319.45682, 542.3967 ]], dtype=float32), array([ 1,  7, 16]), array([0.99545461, 0.91439855, 0.99883264]))\n"
     ]
    }
   ],
   "source": [
    "# 7-main\n",
    "np.random.seed(0)\n",
    "anchors = np.array([[[116, 90], [156, 198], [373, 326]],\n",
    "                    [[30, 61], [62, 45], [59, 119]],\n",
    "                    [[10, 13], [16, 30], [33, 23]]])\n",
    "yolo = Yolo('../data/yolo.h5', '../data/coco_classes.txt', 0.6, 0.5, anchors)\n",
    "predictions, image_paths = yolo.predict('../data/yolo')\n",
    "for i, name in enumerate(image_paths):\n",
    "    if \"dog.jpg\" in name:\n",
    "        ind = i \n",
    "        break\n",
    "print(image_paths[ind])\n",
    "print(predictions[ind])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
