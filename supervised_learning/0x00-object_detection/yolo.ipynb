{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 11:01:49.944289: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-17 11:01:51.411158: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-17 11:01:51.411289: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import tensorflow.keras as K\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO Class\n",
    "# Task 1. Process Outputs\n",
    "class Yolo:\n",
    "    \"\"\"\n",
    "    Initialize Yolo class.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_path, classes_path, class_t, nms_t, anchors):\n",
    "        \"\"\"\n",
    "        Class Constructor\n",
    "        model_path: path to where Darnket Keras model is stored\n",
    "        classes_path: path to list of class names used for Darknet model\n",
    "        class_t: float representing box score threshold for initial filtering\n",
    "        nms_t: float representing the IOU threshold for non-max suppression\n",
    "        anchors: numpy.ndarray of shape (outputs, anchor_boxes, 2) containing\n",
    "        the anchor boxes\n",
    "            outputs: number of outputs made by the Darknet model\n",
    "            anchor_boxes: number of anchor boxes used for each prediction\n",
    "            2: [anchor_box_width, anchor_box_height]\n",
    "        \n",
    "        Public Instance Attributes\n",
    "            model: Darknet Keras Model\n",
    "            class_names: list of the class names for the model\n",
    "            class_t: box score threshold for initial filtering\n",
    "            nms_t: IOU threshold for non-max suppression\n",
    "            anchors: the anchor boxes\n",
    "        \"\"\"\n",
    "        self.model = K.models.load_model(model_path)\n",
    "        with open(classes_path) as file:\n",
    "            class_names = file.read()\n",
    "        self.class_names = class_names.replace(\"\\n\", \"|\").split(\"|\")[:-1]\n",
    "        self.class_t = class_t\n",
    "        self.nms_t = nms_t\n",
    "        self.anchors = anchors\n",
    "\n",
    "    def process_outputs(self, outputs, image_size):\n",
    "        \"\"\"\n",
    "        Process outputs of Darknet model\n",
    "        outputs: numpy.ndarray containing predictions for a single image\n",
    "            Each output will have the shape (grid_height,\n",
    "                                             grid_width,\n",
    "                                             anchor_boxes,\n",
    "                                             4 + 1 + classes)\n",
    "                grid_height: height of grid used for output\n",
    "                grid_width: width of grid used for output\n",
    "                anchor_boxes: number of anchor boxes used\n",
    "                4: t_x, t_y, t_w, t_h\n",
    "                1: box confidence\n",
    "                classes: class probabilities for all classes\n",
    "        image_size: numpy.ndarray containing the original image size\n",
    "            [image_height, image_width]\n",
    "\n",
    "        Returns a tuple of (boxes, box_confidences, box_class_probs)\n",
    "            boxes: list of numpy.ndarrays of shape (grid_height,\n",
    "                                                    grid_width,\n",
    "                                                    anchor_boxes,\n",
    "                                                    4)\n",
    "                4: x1, y1, x2, y2\n",
    "                    (x1, y1, x2, y2) should represent the boundary box relative\n",
    "                    to original image\n",
    "            box_confidences: a list of numpy.ndarrays of shape (grid_height,\n",
    "                                                                grid_width,\n",
    "                                                                anchor_boxes,\n",
    "                                                                classes)\n",
    "                containing the confidences for each output, respectively\n",
    "            box_class_probs: list of numpy.ndarrays of shape (grid_height,\n",
    "                                                              grid_width,\n",
    "                                                              anchor_boxes,\n",
    "                                                              classes)\n",
    "                containing the box's class probabilities for each output\n",
    "        \"\"\"\n",
    "        # Create lists for return\n",
    "        box_confidences, box_class_probs = [], []\n",
    "        boxes = [output[..., :4] for output in outputs]\n",
    "\n",
    "        # Create lists for bounding box corner coordinates\n",
    "        x_corners, y_corners = [], []\n",
    "\n",
    "        # Define sigmoid activation function\n",
    "        def sigmoid(z):\n",
    "            \"\"\"\n",
    "            sigmoid activation function\n",
    "            \"\"\"\n",
    "            return (1 / (1 + np.exp(-z)))\n",
    "\n",
    "        # Creat all of the grid cells to overlay image\n",
    "        # Calculate box_confidences and box_class_probs\n",
    "        for output in outputs:\n",
    "            grid_height = output.shape[0]\n",
    "            grid_width = output.shape[1]\n",
    "            anchors = output.shape[2]\n",
    "\n",
    "            cx = np.arange(grid_width).reshape(1, grid_width)\n",
    "            cx = np.repeat(cx, grid_height, axis=0)\n",
    "            x_corners.append(np.repeat(cx[..., np.newaxis], anchors, axis=2))\n",
    "            cy = np.arange(grid_width).reshape(1, grid_width)\n",
    "            cy = np.repeat(cy, grid_height, axis=0).T\n",
    "            y_corners.append(np.repeat(cy[..., np.newaxis], anchors, axis=2))\n",
    "\n",
    "            box_confidences.append(sigmoid(output[..., 4:5]))\n",
    "            box_class_probs.append(sigmoid(output[..., 5:]))\n",
    "\n",
    "        input_width = self.model.input.shape[1]\n",
    "        input_height = self.model.input.shape[2]\n",
    "\n",
    "        for x, box in enumerate(boxes):\n",
    "            # Activate bounding boxes\n",
    "            bx = (sigmoid(box[..., 0]) + x_corners[x])/outputs[x].shape[1]\n",
    "            by = (sigmoid(box[..., 1]) + y_corners[x])/outputs[x].shape[0]\n",
    "            bw = (np.exp(box[..., 2]) * self.anchors[x, :, 0]) / input_width\n",
    "            bh = (np.exp(box[..., 3]) * self.anchors[x, :, 1]) / input_height\n",
    "\n",
    "            # Move bounding box coordinates from corner to center\n",
    "            box[..., 1] = (by - (bh * .5)) * image_size[0]\n",
    "            box[..., 0] = (bx - (bw * .5)) * image_size[1]\n",
    "            box[..., 3] = (by + (bh * .5)) * image_size[0]\n",
    "            box[..., 2] = (bx + (bw * .5)) * image_size[1]\n",
    "\n",
    "        return (boxes, box_confidences, box_class_probs)\n",
    "\n",
    "    def filter_boxes(self, boxes, box_confidences, box_class_probs):\n",
    "        \"\"\"\n",
    "        Determine which bounding boxes meet or exceed threshold\n",
    "        boxes: list of numpy.ndarrays of shape (grid_height,\n",
    "                                                grid_width,\n",
    "                                                anchor_boxes,\n",
    "                                                4)\n",
    "            containing the processed boundary boxes for each output\n",
    "        box_confidences: list of numpy.ndarrays of shape (grid_height,\n",
    "                                                          grid_width,\n",
    "                                                          anchor_boxes,\n",
    "                                                          1)\n",
    "            containing the processed box confidences for each output\n",
    "        box_class_probs: list of numpy.ndarrays of shape (grid_height,\n",
    "                                                          grid_width,\n",
    "                                                          anchor_boxes,\n",
    "                                                          classes)\n",
    "            containing the preprocessed box class probabilities for each output\n",
    "\n",
    "        Returns a tuple of (filtered_boxes, box_classes, box_scores)\n",
    "            filtered_boxes: numpy.ndarray of shape (?, 4) containing all of the\n",
    "                filtered bounding boxes\n",
    "            box_classes: numpy.ndarray of shape (?,) containing the class\n",
    "                number that each box in filtered_boxes predicts\n",
    "            box_scores: numpy.ndarray of shape (?) containing the box scores\n",
    "                for each box in filtered_boxes\n",
    "        \"\"\"\n",
    "        # Create items for return tuple\n",
    "        filtered_boxes, box_classes, box_scores = None, [], []\n",
    "\n",
    "        for box in range(len(boxes)):\n",
    "            score = np.max(box_class_probs[box] * box_confidences[box],\n",
    "                           axis=3)\n",
    "            cls = np.argmax(box_class_probs[box] * box_confidences[box],\n",
    "                            axis=3)\n",
    "            index = score >= self.class_t\n",
    "\n",
    "            if filtered_boxes is None:\n",
    "                filtered_boxes = boxes[box][index]\n",
    "            else:\n",
    "                filtered_boxes = np.concatenate((filtered_boxes,\n",
    "                                                 boxes[box][index]),\n",
    "                                                 axis=0)\n",
    "            filtered_score = score[index]\n",
    "            filtered_cls = cls[index]\n",
    "\n",
    "            box_classes = np.concatenate((box_classes, filtered_cls), axis=0)\n",
    "            box_scores = np.concatenate((box_scores, filtered_score), axis=0)\n",
    "\n",
    "\n",
    "        return (filtered_boxes, box_classes.astype(int), box_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-main\n",
    "np.random.seed(0)\n",
    "anchors = np.array([[[116, 90], [156, 198], [373, 326]],\n",
    "                    [[30, 61], [62, 45], [59, 119]],\n",
    "                    [[10, 13], [16, 30], [33, 23]]])\n",
    "yolo = Yolo('../data/yolo.h5', '../data/coco_classes.txt', 0.6, 0.5, anchors)\n",
    "yolo.model.summary()\n",
    "print('Class names:', yolo.class_names)\n",
    "print('Class threshold:', yolo.class_t)\n",
    "print('NMS threshold:', yolo.nms_t)\n",
    "print('Anchor boxes:', yolo.anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-main\n",
    "np.random.seed(0)\n",
    "anchors = np.array([[[116, 90], [156, 198], [373, 326]],\n",
    "                    [[30, 61], [62, 45], [59, 119]],\n",
    "                    [[10, 13], [16, 30], [33, 23]]])\n",
    "yolo = Yolo('../data/yolo.h5', '../data/coco_classes.txt', 0.6, 0.5, anchors)\n",
    "output1 = np.random.randn(13, 13, 3, 85)\n",
    "output2 = np.random.randn(26, 26, 3, 85)\n",
    "output3 = np.random.randn(52, 52, 3, 85)\n",
    "boxes, box_confidences, box_class_probs = yolo.process_outputs([output1, output2, output3], np.array([500, 700]))\n",
    "print('Boxes:', boxes)\n",
    "print('Box confidences:', box_confidences)\n",
    "print('Box class probabilities:', box_class_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Boxes: [[-213.74336488 -485.47886784  305.68206077  531.53467019]\n",
      " [ -62.82223363  -11.37138215  156.45267787   70.19663572]\n",
      " [ 190.62733946    7.65943712  319.201764     43.75737906]\n",
      " ...\n",
      " [ 647.78041714  491.58472667  662.00736941  502.60750466]\n",
      " [ 586.27543101  487.95333873  715.85860922  499.39422783]\n",
      " [ 666.1128673   481.29683099  728.88754319  501.09378706]]\n",
      "Box classes: [19 54 29 ... 63 25 46]\n",
      "Box scores: [0.7850503  0.67898563 0.81301861 ... 0.8012832  0.61427808 0.64562072]\n"
     ]
    }
   ],
   "source": [
    "# 2-main\n",
    "np.random.seed(0)\n",
    "anchors = np.array([[[116, 90], [156, 198], [373, 326]],\n",
    "                    [[30, 61], [62, 45], [59, 119]],\n",
    "                    [[10, 13], [16, 30], [33, 23]]])\n",
    "yolo = Yolo('../data/yolo.h5', '../data/coco_classes.txt', 0.6, 0.5, anchors)\n",
    "output1 = np.random.randn(13, 13, 3, 85)\n",
    "output2 = np.random.randn(26, 26, 3, 85)\n",
    "output3 = np.random.randn(52, 52, 3, 85)\n",
    "boxes, box_confidences, box_class_probs = yolo.process_outputs([output1, output2, output3], np.array([500, 700]))\n",
    "boxes, box_classes, box_scores = yolo.filter_boxes(boxes, box_confidences, box_class_probs)\n",
    "print('Boxes:', boxes)\n",
    "print('Box classes:', box_classes)\n",
    "print('Box scores:', box_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-main\n",
    "np.random.seed(0)\n",
    "anchors = np.array([[[116, 90], [156, 198], [373, 326]],\n",
    "                    [[30, 61], [62, 45], [59, 119]],\n",
    "                    [[10, 13], [16, 30], [33, 23]]])\n",
    "yolo = Yolo('../data/yolo.h5', '../data/coco_classes.txt', 0.6, 0.5, anchors)\n",
    "output1 = np.random.randn(13, 13, 3, 85)\n",
    "output2 = np.random.randn(26, 26, 3, 85)\n",
    "output3 = np.random.randn(52, 52, 3, 85)\n",
    "boxes, box_confidences, box_class_probs = yolo.process_outputs([output1, output2, output3], np.array([500, 700]))\n",
    "boxes, box_classes, box_scores = yolo.filter_boxes(boxes, box_confidences, box_class_probs)\n",
    "boxes, box_classes, box_scores = yolo.non_max_suppression(boxes, box_classes, box_scores)\n",
    "print('Boxes:', boxes)\n",
    "print('Box classes:', box_classes)\n",
    "print('Box scores:', box_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-main\n",
    "np.random.seed(0)\n",
    "anchors = np.array([[[116, 90], [156, 198], [373, 326]],\n",
    "                    [[30, 61], [62, 45], [59, 119]],\n",
    "                    [[10, 13], [16, 30], [33, 23]]])\n",
    "yolo = Yolo('../data/yolo.h5', '../data/coco_classes.txt', 0.6, 0.5, anchors)\n",
    "images, image_paths = yolo.load_images('../data/yolo')\n",
    "i = np.random.randint(0, len(images))\n",
    "cv2.imshow(image_paths[i], images[i])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-main\n",
    "np.random.seed(0)\n",
    "anchors = np.array([[[116, 90], [156, 198], [373, 326]],\n",
    "                    [[30, 61], [62, 45], [59, 119]],\n",
    "                    [[10, 13], [16, 30], [33, 23]]])\n",
    "yolo = Yolo('../data/yolo.h5', '../data/coco_classes.txt', 0.6, 0.5, anchors)\n",
    "images, image_paths = yolo.load_images('../data/yolo')\n",
    "pimages, image_shapes = yolo.preprocess_images(images)\n",
    "print(type(pimages), pimages.shape)\n",
    "print(type(image_shapes), image_shapes.shape)\n",
    "i = np.random.randint(0, len(images))\n",
    "print(images[i].shape, ':', image_shapes[i])\n",
    "cv2.imshow(image_paths[i], pimages[i])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6-main\n",
    "np.random.seed(0)\n",
    "anchors = np.array([[[116, 90], [156, 198], [373, 326]],\n",
    "                    [[30, 61], [62, 45], [59, 119]],\n",
    "                    [[10, 13], [16, 30], [33, 23]]])\n",
    "yolo = Yolo('../data/yolo.h5', '../data/coco_classes.txt', 0.6, 0.5, anchors)\n",
    "images, image_paths = yolo.load_images('../data/yolo')\n",
    "boxes = np.array([[119.22100287, 118.62197718, 567.75985556, 440.44121152],\n",
    "                    [468.53530752, 84.48338278, 696.04923556, 167.98947829],\n",
    "                    [124.2043716, 220.43365057, 319.4254314 , 542.13706101]])\n",
    "box_scores = np.array([0.99537075, 0.91536146, 0.9988506])\n",
    "box_classes = np.array([1, 7, 16])\n",
    "ind = 0\n",
    "for i, name in enumerate(image_paths):\n",
    "    if \"dog.jpg\" in name:\n",
    "        ind = i\n",
    "        break\n",
    "yolo.show_boxes(images[i], boxes, box_classes, box_scores, \"dog.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7-main\n",
    "np.random.seed(0)\n",
    "anchors = np.array([[[116, 90], [156, 198], [373, 326]],\n",
    "                    [[30, 61], [62, 45], [59, 119]],\n",
    "                    [[10, 13], [16, 30], [33, 23]]])\n",
    "yolo = Yolo('../data/yolo.h5', '../data/coco_classes.txt', 0.6, 0.5, anchors)\n",
    "predictions, image_paths = yolo.predict('../data/yolo')\n",
    "for i, name in enumerate(image_paths):\n",
    "    if \"dog.jpg\" in name:\n",
    "        ind = i\n",
    "        break\n",
    "print(image_paths[ind])\n",
    "print(predictions[ind])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
