{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "148d5593-4f98-4e56-9cc2-97cbed3da440",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Imports here\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70985a22-2a2e-4fba-b0ba-aa2fba4b034d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 0 - Create Confusion\n",
    "\"\"\"\n",
    "Function that creates a confusion matrix\n",
    "\"\"\"\n",
    "def create_confusion_matrix(labels, logits):\n",
    "    \"\"\"\n",
    "    labels: one-hot numpy.ndarray of shape (m, classes) containing the correct labels\n",
    "        m: number of data points\n",
    "        classes: number of classes\n",
    "    logits: one-hot numpy.ndarray of shape (m, classes) containing the predicted labels\n",
    "    Returns a confusion numpy.ndarray of shape (classes, classes)\n",
    "        row indices: correct labels\n",
    "        column indixes: predicted labels\n",
    "    \"\"\"\n",
    "    confusion_matrix = np.zeros([labels.shape[1], logits.shape[1]])\n",
    "    # print(confusion_matrix)\n",
    "    true_label_index = np.where(labels == 1)[1]\n",
    "    true_logits_index = np.where(logits == 1)[1]\n",
    "    # print(true_label_index)\n",
    "    # print(true_logits_index)\n",
    "    indexes = list(zip(true_label_index, true_logits_index))\n",
    "    unique, counts = np.unique(indexes, return_counts=True, axis=0)\n",
    "    # print(unique)\n",
    "    # print(counts)\n",
    "    confusion_matrix[unique[:,0], unique[:,1]] = counts\n",
    "    # print(confusion_matrix)\n",
    "    \n",
    "    return(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6855fc0d-7662-4687-8221-a08cd07c98f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4701.    0.   36.   17.   12.   81.   38.   11.   35.    1.]\n",
      " [   0. 5494.   36.   21.    3.   38.    7.   13.   59.    7.]\n",
      " [  64.   93. 4188.  103.  108.   17.  162.   80.  132.   21.]\n",
      " [  30.   48.  171. 4310.    2.  252.   22.   86.  128.   52.]\n",
      " [  17.   27.   35.    0. 4338.   11.   84.    9.   27.  311.]\n",
      " [  89.   57.   45.  235.   70. 3631.  123.   33.  163.   60.]\n",
      " [  47.   32.   87.    1.   64.   83. 4607.    0.   29.    1.]\n",
      " [  26.   95.   75.    7.   58.   18.    1. 4682.   13.  200.]\n",
      " [  31.  153.   82.  174.   27.  179.   64.    7. 4003.  122.]\n",
      " [  48.   37.   39.   71.  220.   49.    8.  244.   46. 4226.]]\n"
     ]
    }
   ],
   "source": [
    "# 0-main\n",
    "lib = np.load('labels_logits.npz')\n",
    "labels = lib['labels']\n",
    "logits = lib['logits']\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "confusion = create_confusion_matrix(labels, logits)\n",
    "print(confusion)\n",
    "np.savez_compressed('confusion.npz', confusion=confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25abab10-692d-4c0a-ac44-0770f1874c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1 - Sensitivity\n",
    "\"\"\"\n",
    "Function that calculates the sensitivity for each class in a confusion matrix\n",
    "\"\"\"\n",
    "def sensitivity(confusion):\n",
    "    \"\"\"\n",
    "    confusion: numpy.ndarray of shape (classes, classes)\n",
    "        row: indices that represent the correct labels\n",
    "        column: indices that represent the predicted labels\n",
    "    Returns a numpy.ndarray of shape (classes, ) containing the sensitivity of\n",
    "        each class\n",
    "    \"\"\"\n",
    "    true_positives = np.diag(confusion)\n",
    "    row_sum = np.sum(confusion, axis=1)\n",
    "    false_negative = row_sum - true_positives\n",
    "    sensitivity = true_positives / (true_positives + false_negative)\n",
    "    return sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08354430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95316302 0.96759422 0.84299517 0.84493237 0.89277629 0.80581447\n",
      " 0.93051909 0.9047343  0.82672449 0.84723336]\n"
     ]
    }
   ],
   "source": [
    "# 1-main\n",
    "confusion = np.load('confusion.npz')['confusion']\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "print(sensitivity(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81a1fe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2 - Precision\n",
    "\"\"\"\n",
    "Function that calculates the precision for each class in a confusion matrix\n",
    "\"\"\"\n",
    "def precision(confusion):\n",
    "    \"\"\"\n",
    "    confusion: numpy.ndarray of shape (classes, classes)\n",
    "        row: indices that represent the correct labels\n",
    "        column: indices that represent the predicted labels\n",
    "    Returns a numpy.ndarray of shape (classes, ) containing the precision of\n",
    "        each class\n",
    "    \"\"\"\n",
    "    true_positives = np.diag(confusion)\n",
    "    col_sum = np.sum(confusion, axis=0)\n",
    "    false_positives = col_sum - true_positives\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0656ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93033841 0.91020543 0.87359199 0.87264628 0.88494492 0.83298922\n",
      " 0.90050821 0.90648596 0.86364617 0.84503099]\n"
     ]
    }
   ],
   "source": [
    "# 2-main\n",
    "confusion = np.load('confusion.npz')['confusion']\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "print(precision(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fd73f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3. Specificity\n",
    "\"\"\"\n",
    "Function that calculates the specificity for each class in a confusion matrix\n",
    "\"\"\"\n",
    "def specificity(confusion):\n",
    "    \"\"\"\n",
    "    confusion: numpy.ndarray of shape (classes, classes)\n",
    "        row: indices that represent the correct labels\n",
    "        column: indices that represent the predicted labels\n",
    "    Returns a numpy.ndarray of shape (classes, ) containing the specificity of\n",
    "        each class\n",
    "    \"\"\"\n",
    "    true_positives = np.diag(confusion)\n",
    "    col_sum = np.sum(confusion, axis=0)\n",
    "    false_positives = col_sum - true_positives\n",
    "    row_sum = np.sum(confusion, axis=1)\n",
    "    false_negatives = row_sum - true_positives\n",
    "    true_negatives = np.sum(confusion) - true_positives - false_positives - false_negatives\n",
    "    speficity = true_negatives / (true_negatives + false_positives)\n",
    "    return speficity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60111abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91553398 0.94039083 0.91365132 0.92460589 0.91623693 0.92398695\n",
      " 0.95227556 0.93264469 0.91346974 0.91496309 0.92830757 0.92361305\n",
      " 0.92094371]\n"
     ]
    }
   ],
   "source": [
    "# 3-main\n",
    "np.random.seed(5)\n",
    "c = np.random.randint(10, 20)\n",
    "confusion = np.random.randint(0, 100, (c, c))\n",
    "print(specificity(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9007ae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4 - F1 score\n",
    "\"\"\"\n",
    "Calculate the F1 score of a confusion matrix\n",
    "\"\"\"\n",
    "def f1_score(confusion):\n",
    "    \"\"\"\n",
    "    confusion: numpy.ndarray of shape (classes, classes)\n",
    "        row: indices that represent the correct labels\n",
    "        column: indices that represent the predicted labels\n",
    "    Returns a numpy.ndarray of shape (classes, ) containing the F1 score of\n",
    "        each class\n",
    "    \"\"\"\n",
    "    # prec = precision(confusion)\n",
    "    # sens = sensitivity(confusion)\n",
    "    # F1 = prec + sens\n",
    "    # return F1 / 2\n",
    "    \n",
    "    \n",
    "    true_positives = np.diag(confusion)\n",
    "    col_sum = np.sum(confusion, axis=0)\n",
    "    false_positives = col_sum - true_positives\n",
    "    row_sum = np.sum(confusion, axis=1)\n",
    "    false_negatives = row_sum - true_positives\n",
    "    F1 = (2 * true_positives) / ((2 * true_positives) + false_positives + false_negatives)\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42d61a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94161242 0.93802288 0.8580209  0.85856574 0.88884336 0.81917654\n",
      " 0.91526771 0.90560928 0.8447821  0.84613074]\n"
     ]
    }
   ],
   "source": [
    "# 4-main\n",
    "confusion = np.load('confusion.npz')['confusion']\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "print(f1_score(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8317f493",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
