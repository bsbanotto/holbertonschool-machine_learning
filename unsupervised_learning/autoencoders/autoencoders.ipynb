{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 10:54:58.618360: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-29 10:54:59.156252: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-06-29 10:54:59.156335: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import tensorflow.keras as keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 0\n",
    "def vanilla_autoencoder(input_dims, hidden_layers, latent_dims):\n",
    "    \"\"\"\n",
    "    Creates a vanilla autoencoder\n",
    "\n",
    "    Args:\n",
    "        input_dims - integer containing the dimensions of the model input\n",
    "        hidden_layers - list containing the number of nodes for each hidden\n",
    "            layer in the encoder, respectively\n",
    "        latent_dims - integer containing the dimensions of the latent space\n",
    "            representation\n",
    "\n",
    "    Returns:\n",
    "        encoder - the encoder model\n",
    "        decoder - the decoder model\n",
    "        auto - the full autoencoder model\n",
    "    \"\"\"\n",
    "\n",
    "    # First, build the encoder\n",
    "    input_img = keras.Input(shape=(input_dims,))\n",
    "    encoded = input_img\n",
    "    for layer in hidden_layers:\n",
    "        encoded = keras.layers.Dense(layer, activation='relu')(encoded)\n",
    "    encoded = keras.layers.Dense(latent_dims, activation='relu')(encoded)\n",
    "    encoder = keras.Model(input_img, encoded, name='encoder')\n",
    "\n",
    "    # Now, build the decoder\n",
    "    decoder_img = keras.Input(shape=(latent_dims,))\n",
    "    decoded = decoder_img\n",
    "    for layer in hidden_layers[::-1]:\n",
    "        decoded = keras.layers.Dense(layer, activation='relu')(decoded)\n",
    "    decoded = keras.layers.Dense(input_dims, activation='sigmoid')(decoded)\n",
    "    decoder = keras.Model(decoder_img, decoded, name='decoder')\n",
    "\n",
    "    # Let's put it all together\n",
    "    encoded_output = encoder(input_img)\n",
    "    decoded_output = decoder(encoded_output)\n",
    "    autoencoder = keras.Model(input_img,\n",
    "                              decoded_output,\n",
    "                              name='autoencoder')\n",
    "\n",
    "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "    return encoder, decoder, autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-main\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# autoencoder = __import__('0-vanilla').autoencoder\n",
    "\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((-1, 784))\n",
    "x_test = x_test.reshape((-1, 784))\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)\n",
    "encoder, decoder, auto = vanilla_autoencoder(784, [128, 64], 32)\n",
    "auto.fit(x_train, x_train, epochs=50,batch_size=256, shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n",
    "encoded = encoder.predict(x_test[:10])\n",
    "print(np.mean(encoded))\n",
    "reconstructed = decoder.predict(encoded)\n",
    "\n",
    "for i in range(10):\n",
    "    ax = plt.subplot(2, 10, i + 1)\n",
    "    ax.axis('off')\n",
    "    plt.imshow(x_test[i].reshape((28, 28)))\n",
    "    ax = plt.subplot(2, 10, i + 11)\n",
    "    ax.axis('off')\n",
    "    plt.imshow(reconstructed[i].reshape((28, 28)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1 - Sparse autoencoder\n",
    "# Add a lambtha, to be used as the L1 paramater for regularization\n",
    "\n",
    "def sparse_autoencoder(input_dims, hidden_layers, latent_dims, lambtha):\n",
    "    \"\"\"\n",
    "    Creates a sparse autoencoder\n",
    "\n",
    "        Args:\n",
    "        input_dims - integer containing the dimensions of the model input\n",
    "        hidden_layers - list containing the number of nodes for each hidden\n",
    "            layer in the encoder, respectively\n",
    "        latent_dims - integer containing the dimensions of the latent space\n",
    "            representation\n",
    "        lambtha - regularization paramater used for L1 regularization on the\n",
    "            encoded output\n",
    "\n",
    "    Returns:\n",
    "        encoder - the encoder model\n",
    "        decoder - the decoder model\n",
    "        auto - the full autoencoder model\n",
    "    \"\"\"\n",
    "\n",
    "    # Create reg variable to keep line length short\n",
    "    reg = keras.regularizers.l1(lambtha)\n",
    "\n",
    "    # First, build the encoder\n",
    "    input_img = keras.Input(shape=(input_dims,))\n",
    "    encoded = input_img\n",
    "    for layer in hidden_layers:\n",
    "        encoded = keras.layers.Dense(layer,\n",
    "                                     activation='relu'\n",
    "                                     )(encoded)\n",
    "    encoded = keras.layers.Dense(latent_dims,\n",
    "                                 activation='relu',\n",
    "                                 activity_regularizer=reg\n",
    "                                 )(encoded)\n",
    "    encoder = keras.Model(input_img, encoded, name='encoder')\n",
    "\n",
    "    # Now, build the decoder\n",
    "    decoder_img = keras.Input(shape=(latent_dims,))\n",
    "    decoded = decoder_img\n",
    "    for layer in hidden_layers[::-1]:\n",
    "        decoded = keras.layers.Dense(layer, activation='relu')(decoded)\n",
    "    decoded = keras.layers.Dense(input_dims, activation='sigmoid')(decoded)\n",
    "    decoder = keras.Model(decoder_img, decoded, name='decoder')\n",
    "\n",
    "    # Let's put it all together\n",
    "    encoded_output = encoder(input_img)\n",
    "    decoded_output = decoder(encoded_output)\n",
    "    autoencoder = keras.Model(input_img,\n",
    "                              decoded_output,\n",
    "                              name='autoencoder')\n",
    "\n",
    "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "    return encoder, decoder, autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-main\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((-1, 784))\n",
    "x_test = x_test.reshape((-1, 784))\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)\n",
    "encoder, decoder, auto = sparse_autoencoder(784, [128, 64], 32, 10e-6)\n",
    "auto.fit(x_train, x_train, epochs=100,batch_size=256, shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n",
    "encoded = encoder.predict(x_test[:10])\n",
    "print(np.mean(encoded))\n",
    "reconstructed = decoder.predict(encoded)\n",
    "\n",
    "for i in range(10):\n",
    "    ax = plt.subplot(2, 10, i + 1)\n",
    "    ax.axis('off')\n",
    "    plt.imshow(x_test[i].reshape((28, 28)))\n",
    "    ax = plt.subplot(2, 10, i + 11)\n",
    "    ax.axis('off')\n",
    "    plt.imshow(reconstructed[i].reshape((28, 28)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Autoencoder\n",
    "def conv_autoencoder(input_dims, filters, latent_dims):\n",
    "    \"\"\"\n",
    "    Create a convolutional autoencoder\n",
    "\n",
    "    Each convolution in the encoder and decoder should use a kernel size of\n",
    "        (3, 3) with same padding and relu activation followed by max pooling\n",
    "        size of (2, 2)\n",
    "\n",
    "    Args:\n",
    "        input_dims - tuple of integers containing the dimensions of the input\n",
    "        filters - list containing the number of filters for each convolutional\n",
    "            layer in the encoder, respectively\n",
    "        The filters should be reversed for the decoder\n",
    "        latent_dims - tuple of integers containing the dimensions of the latent\n",
    "            space representation\n",
    "\n",
    "    Returns:\n",
    "        encoder - the encoder model\n",
    "        decoder - the decoder model\n",
    "        auto - the full autoencoder model\n",
    "    \"\"\"\n",
    "    # i = 0\n",
    "    # Build the encoder\n",
    "    input_img = keras.Input(shape=input_dims)\n",
    "    encoded = input_img\n",
    "    for filter in filters:\n",
    "        encoded = keras.layers.Conv2D(filter,\n",
    "                                      (3, 3),\n",
    "                                      activation='relu',\n",
    "                                      padding='same')(encoded)\n",
    "        encoded = keras.layers.MaxPooling2D((2, 2),\n",
    "                                            padding='same')(encoded)\n",
    "    encoder = keras.Model(input_img, encoded, name='encoder')\n",
    "\n",
    "    # Build the decoder\n",
    "    decoder_img = keras.Input(shape=latent_dims)\n",
    "    decoded = decoder_img\n",
    "    # print(filters[0])\n",
    "    # print(filters[1])\n",
    "    # print(filters[2])\n",
    "    # Loop through filters backwards\n",
    "    # for filter in filters[1::-1]:\n",
    "    #     print(\"loop: \" + str(i))\n",
    "    #     print(filter)\n",
    "    #     i += 1\n",
    "    #     decoded = keras.layers.Conv2D(filter - 1,\n",
    "    #                                   (3, 3),\n",
    "    #                                   activation='relu',\n",
    "    #                                   padding='same')(decoded)\n",
    "    #     decoded = keras.layers.UpSampling2D((2, 2))(decoded)\n",
    "    # print(filters[0])\n",
    "    # Going to try to manually loop\n",
    "    decoded = keras.layers.Conv2D(filters[2],\n",
    "                                  (3, 3),\n",
    "                                  activation='relu',\n",
    "                                  padding='same')(decoded)\n",
    "    decoded = keras.layers.UpSampling2D((2, 2))(decoded)\n",
    "    \n",
    "    decoded = keras.layers.Conv2D(filters[1],\n",
    "                                  (3, 3),\n",
    "                                  activation='relu',\n",
    "                                  padding='same')(decoded)\n",
    "    decoded = keras.layers.UpSampling2D((2, 2))(decoded)\n",
    "\n",
    "    decoded = keras.layers.Conv2D(filters[0],\n",
    "                                  (3, 3),\n",
    "                                  activation='relu',\n",
    "                                  padding='valid')(decoded)\n",
    "    decoded = keras.layers.UpSampling2D((2, 2))(decoded)\n",
    "    # print(\"Exited loop\")\n",
    "    decoded = keras.layers.Conv2D(1,\n",
    "                                  (3, 3),\n",
    "                                  activation='sigmoid',\n",
    "                                  padding='same')(decoded)\n",
    "    decoder = keras.Model(decoder_img,\n",
    "                          decoded,\n",
    "                          name='decoder')\n",
    "\n",
    "    # Bring it all together\n",
    "    encoded_output = encoder(input_img)\n",
    "    decoded_output = decoder(encoded_output)\n",
    "    autoencoder = keras.Model(input_img,\n",
    "                              decoded_output,\n",
    "                              name='autoencoder')\n",
    "\n",
    "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "    return encoder, decoder, autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-main\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.expand_dims(x_train, axis=3)\n",
    "x_test = np.expand_dims(x_test, axis=3)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)\n",
    "encoder, decoder, auto = conv_autoencoder((28, 28, 1), [16, 8, 8], (4, 4, 8))\n",
    "auto.fit(x_train, x_train, epochs=50, batch_size=256, shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n",
    "encoded = encoder.predict(x_test[:10])\n",
    "print(np.mean(encoded))\n",
    "reconstructed = decoder.predict(encoded)[:,:,:,0]\n",
    "\n",
    "for i in range(10):\n",
    "    ax = plt.subplot(2, 10, i + 1)\n",
    "    ax.axis('off')\n",
    "    plt.imshow(x_test[i,:,:,0])\n",
    "    ax = plt.subplot(2, 10, i + 11)\n",
    "    ax.axis('off')\n",
    "    plt.imshow(reconstructed[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3 - Variational Autoencoder\n",
    "\n",
    "def var_autoencoder(input_dims, hidden_layers, latent_dims):\n",
    "    \"\"\"\n",
    "    Create a variational autoencoder\n",
    "\n",
    "    Args:\n",
    "        input_dims - integer containing the dimension of the input\n",
    "        hidden_layers - list containing the number of nodes for each hidden\n",
    "            layer in the encoder, respectively\n",
    "        The filters should be reversed for the decoder\n",
    "        latent_dims - integer containing the dimension of the latent\n",
    "            space representation\n",
    "\n",
    "    Returns:\n",
    "        encoder - the encoder model, which should output the latent\n",
    "            representation, the mena, and the log variance, respectively\n",
    "        decoder - the decoder model\n",
    "        auto - the full autoencoder model\n",
    "    \"\"\"\n",
    "    def sampling(args):\n",
    "        \"\"\"\n",
    "        Method to sample new, similar points from the latent space\n",
    "        \"\"\"\n",
    "        z_mean, z_log_sigma = args\n",
    "        shape = keras.backend.shape(z_mean)[0], latent_dims\n",
    "        epsilon = keras.backend.random_normal(shape=shape, mean=0, stddev=0.1)\n",
    "\n",
    "        return z_mean + keras.backend.exp(z_log_sigma) * epsilon\n",
    "\n",
    "    # First, build the encoder\n",
    "    input_img = keras.Input(shape=(input_dims,))\n",
    "\n",
    "    h = input_img\n",
    "    for layer in hidden_layers:\n",
    "        h = keras.layers.Dense(layer, activation='relu')(h)\n",
    "\n",
    "    # h = keras.layers.Dense(latent_dims)(h)\n",
    "    z_mean = keras.layers.Dense(latent_dims)(h)\n",
    "    z_log_sigma = keras.layers.Dense(latent_dims)(h)\n",
    "\n",
    "    z = keras.layers.Lambda(sampling)([z_mean, z_log_sigma])\n",
    "\n",
    "    encoder = keras.Model(input_img, [z_mean, z_log_sigma, z], name='encoder')\n",
    "\n",
    "    # I think I'm below here. Seems to be the encoder that's failing\n",
    "\n",
    "    # Now the decoder\n",
    "    latent_inputs = keras.Input(shape=(latent_dims,))\n",
    "\n",
    "    x = latent_inputs\n",
    "    for layer in hidden_layers[1::-1]:\n",
    "        x = keras.layers.Dense(layer, activation='relu')(x)\n",
    "    outputs = keras.layers.Dense(input_dims, activation='sigmoid')(x)\n",
    "    decoder = keras.Model(latent_inputs, outputs, name='decoder')\n",
    "\n",
    "    # instantiate the VAE model\n",
    "    outputs = decoder(encoder(input_img)[2])\n",
    "    vae = keras.Model(input_img, outputs, name='vae_mlp')\n",
    "\n",
    "    reconstruction_loss = keras.losses.binary_crossentropy(input_img,\n",
    "                                                           outputs)\n",
    "    reconstruction_loss *= input_dims\n",
    "    kl_loss = 1 + z_log_sigma - keras.backend.square(z_mean)\n",
    "    kl_loss -= keras.backend.exp(z_log_sigma)\n",
    "    kl_loss = keras.backend.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    vae_loss = keras.backend.mean(reconstruction_loss + kl_loss)\n",
    "    vae.add_loss(vae_loss)\n",
    "    vae.compile(optimizer='adam')\n",
    "\n",
    "    return encoder, decoder, vae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "layers = keras.layers\n",
    "Model = keras.Model\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = tf.shape(z_mean)[0]\n",
    "    dim = tf.shape(z_mean)[1]\n",
    "    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "def var_autoencoder(input_dims, hidden_layers, latent_dims):\n",
    "    # Encoder\n",
    "    encoder_inputs = layers.Input(shape=(input_dims,))\n",
    "    x = encoder_inputs\n",
    "    for units in hidden_layers:\n",
    "        x = layers.Dense(units, activation='relu')(x)\n",
    "    z_mean = layers.Dense(latent_dims)(x)\n",
    "    z_log_var = layers.Dense(latent_dims)(x)\n",
    "    z = layers.Lambda(sampling)([z_mean, z_log_var])\n",
    "    encoder = Model(encoder_inputs, [z, z_mean, z_log_var])\n",
    "\n",
    "    # Decoder\n",
    "    latent_inputs = layers.Input(shape=(latent_dims,))\n",
    "    x = latent_inputs\n",
    "    for units in reversed(hidden_layers):\n",
    "        x = layers.Dense(units, activation='relu')(x)\n",
    "    decoder_outputs = layers.Dense(input_dims, activation='sigmoid')(x)\n",
    "    decoder = Model(latent_inputs, decoder_outputs)\n",
    "\n",
    "    # Full Autoencoder\n",
    "    autoencoder_outputs = decoder(encoder(encoder_inputs)[0])\n",
    "    autoencoder = Model(encoder_inputs, autoencoder_outputs)\n",
    "\n",
    "    # Compile the autoencoder\n",
    "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "    return encoder, decoder, autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-main\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((-1, 784))\n",
    "x_test = x_test.reshape((-1, 784))\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)\n",
    "encoder, decoder, auto = var_autoencoder(784, [512], 2)\n",
    "auto.fit(x_train, x_train, epochs=50, batch_size=256, shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n",
    "encoded, mu, log_sig = encoder.predict(x_test[:10])\n",
    "print(mu)\n",
    "print(np.exp(log_sig / 2))\n",
    "reconstructed = decoder.predict(encoded).reshape((-1, 28, 28))\n",
    "x_test = x_test.reshape((-1, 28, 28))\n",
    "\n",
    "for i in range(10):\n",
    "    ax = plt.subplot(2, 10, i + 1)\n",
    "    ax.axis('off')\n",
    "    plt.imshow(x_test[i])\n",
    "    ax = plt.subplot(2, 10, i + 11)\n",
    "    ax.axis('off')\n",
    "    plt.imshow(reconstructed[i])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "l1 = np.linspace(-3, 3, 25)\n",
    "l2 = np.linspace(-3, 3, 25)\n",
    "L = np.stack(np.meshgrid(l1, l2, sparse=False, indexing='ij'), axis=2)\n",
    "G = decoder.predict(L.reshape((-1, 2)), batch_size=125)\n",
    "\n",
    "for i in range(25*25):\n",
    "    ax = plt.subplot(25, 25, i + 1)\n",
    "    ax.axis('off')\n",
    "    plt.imshow(G[i].reshape((28, 28)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 13:30:44.341936: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-06-29 13:30:44.342146: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-06-29 13:30:44.342214: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (BensLaptop): /proc/driver/nvidia/version does not exist\n",
      "2023-06-29 13:30:44.345695: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Checker Main File\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# autoencoder = __import__('3-variational').autoencoder\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)\n",
    "encoder, decoder, auto = var_autoencoder(784, [512, 256], 2)\n",
    "if len(auto.layers) == 3:\n",
    "    print(auto.layers[0].input_shape == [(None, 784)])\n",
    "    print(auto.layers[1] is encoder)\n",
    "    print(auto.layers[2] is decoder)\n",
    "\n",
    "with open('1-test', 'w+') as f:\n",
    "    x_test = np.load(\"/home/bsbanotto/holbertonschool-machine_learning/supervised_learning/data/MNIST.npz\")[\"X_test\"]\n",
    "    x_test = x_test[:256].reshape((-1, 784))\n",
    "    f.write(np.format_float_scientific(auto.evaluate(x_test, x_test, verbose=False), precision=6) + '\\n')\n",
    "    f.write(auto.optimizer.__class__.__name__ + '\\n')\n",
    "\n",
    "with open('2-test', 'w+') as f:\n",
    "    try:\n",
    "        f.write(encoder.layers[0].__class__.__name__ + '\\n')\n",
    "        f.write(str(encoder.layers[0].input_shape) + '\\n')\n",
    "    except:\n",
    "        f.write('FAIL\\n')\n",
    "    for layer in encoder.layers[1:]:\n",
    "        try:\n",
    "            f.write(layer.__class__.__name__ + '\\n')\n",
    "            if layer.__class__.__name__ == 'Dense':\n",
    "                if layer.activation is not None:\n",
    "                    f.write(layer.activation.__name__ + '\\n')\n",
    "                f.write(str(layer.input_shape) + '\\n')\n",
    "                f.write(str(layer.output_shape) + '\\n')\n",
    "            elif layer.__class__.__name__ == 'Lambda':\n",
    "                assert(len(layer.input) == 2)\n",
    "                assert(encoder.layers[-3].output in layer.input)\n",
    "                assert(encoder.layers[-2].output in layer.input)\n",
    "                f.write(str(layer.input_shape) + '\\n')\n",
    "                f.write(str(layer.output_shape) + '\\n')\n",
    "        except:\n",
    "            f.write('FAIL\\n')\n",
    "\n",
    "with open('3-test', 'w+') as f:\n",
    "    try:\n",
    "        f.write(decoder.layers[0].__class__.__name__ + '\\n')\n",
    "        f.write(str(decoder.layers[0].input_shape) + '\\n')\n",
    "    except:\n",
    "        f.write('FAIL\\n')\n",
    "    for layer in decoder.layers[1:]:\n",
    "        try:\n",
    "            f.write(layer.__class__.__name__ + '\\n')\n",
    "            if layer.__class__.__name__ == 'Dense' and layer.activation != None:\n",
    "                f.write(layer.activation.__name__ + '\\n')\n",
    "            f.write(str(layer.input_shape) + '\\n')\n",
    "            f.write(str(layer.output_shape) + '\\n')\n",
    "        except:\n",
    "            f.write('FAIL\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
